{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pg_graphql Documentation : https://supabase.github.io/pg_graphql Source Code : https://github.com/supabase/pg_graphql pg_graphql adds GraphQL support to your PostgreSQL database. Performant Consistent Open Source Overview pg_graphql is a PostgreSQL extension that enables querying the database with GraphQL using a single SQL function. The extension reflects a GraphQL schema from the existing SQL schema and exposes it through a SQL function, graphql.resolve(...) . This enables any programming language that can connect to PostgreSQL to query the database via GraphQL with no additional servers, processes, or libraries. TL;DR The SQL schema 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 create table account ( id serial primary key , email varchar ( 255 ) not null , created_at timestamp not null , updated_at timestamp not null ); create table blog ( id serial primary key , owner_id integer not null references account ( id ), name varchar ( 255 ) not null , description varchar ( 255 ), created_at timestamp not null , updated_at timestamp not null ); create type blog_post_status as enum ( 'PENDING' , 'RELEASED' ); create table blog_post ( id uuid not null default uuid_generate_v4 () primary key , blog_id integer not null references blog ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ), status blog_post_status not null , created_at timestamp not null , updated_at timestamp not null ); Translates into a GraphQL schema displayed below. Each table receives an entrypoint in the top level Query type that is a pageable collection with relationships defined by its foreign keys. Tables similarly receive entrypoints in the Mutation type that enable bulk operations for insert, update, and delete.","title":"Welcome"},{"location":"#pg_graphql","text":"Documentation : https://supabase.github.io/pg_graphql Source Code : https://github.com/supabase/pg_graphql pg_graphql adds GraphQL support to your PostgreSQL database. Performant Consistent Open Source","title":"pg_graphql"},{"location":"#overview","text":"pg_graphql is a PostgreSQL extension that enables querying the database with GraphQL using a single SQL function. The extension reflects a GraphQL schema from the existing SQL schema and exposes it through a SQL function, graphql.resolve(...) . This enables any programming language that can connect to PostgreSQL to query the database via GraphQL with no additional servers, processes, or libraries.","title":"Overview"},{"location":"#tldr","text":"The SQL schema 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 create table account ( id serial primary key , email varchar ( 255 ) not null , created_at timestamp not null , updated_at timestamp not null ); create table blog ( id serial primary key , owner_id integer not null references account ( id ), name varchar ( 255 ) not null , description varchar ( 255 ), created_at timestamp not null , updated_at timestamp not null ); create type blog_post_status as enum ( 'PENDING' , 'RELEASED' ); create table blog_post ( id uuid not null default uuid_generate_v4 () primary key , blog_id integer not null references blog ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ), status blog_post_status not null , created_at timestamp not null , updated_at timestamp not null ); Translates into a GraphQL schema displayed below. Each table receives an entrypoint in the top level Query type that is a pageable collection with relationships defined by its foreign keys. Tables similarly receive entrypoints in the Mutation type that enable bulk operations for insert, update, and delete.","title":"TL;DR"},{"location":"api/","text":"In our API, each SQL table is reflected as a set of GraphQL types. At a high level, tables become types and columns/foreign keys become fields on those types. By default, PostgreSQL table and column names are not inflected when reflecting GraphQL names. For example, an account_holder table has GraphQL type name account_holder . In cases where SQL entities are named using snake_case , enable inflection to match GraphQL/Javascript conventions e.g. account_holder -> AccountHolder . Individual table, column, and relationship names may also be manually overridden . Primary Keys (Required) Every table must have a primary key for it to be exposed in the GraphQL schema. For example, the following Blog table will be available in the GraphQL schema as blogCollection since it has a primary key named id : 1 2 3 4 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , ); But the following table will not be exposed because it doesn't have a primary key: 1 2 3 4 create table \"Blog\" ( id int , name varchar ( 255 ) not null , ); QueryType The Query type is the entrypoint for all read access into the graph. Node The node interface allows for retrieving records that are uniquely identifiable by a globally unique nodeId: ID! field. For more information about nodeId, see nodeId . SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null , \"updatedAt\" timestamp not null ); GraphQL Types QueryType 1 2 3 4 5 6 7 \"\"\"The root type for querying data\"\"\" type Query { \"\"\"Retrieve a record by its `ID`\"\"\" node ( nodeId: ID !): Node } To query the node interface effectively, use inline fragments to specify which fields to return for each type. Example Query Response 1 2 3 4 5 6 7 8 9 10 11 12 { node ( nodeId: \"WyJwdWJsaWMiLCAiYmxvZyIsIDFd\" ) { nodeId # Inline fragment for `Blog` type ... on Blog { name description } } } 1 2 3 4 5 6 7 8 9 { \"data\" : { \"node\" : { \"name\" : \"Some Blog\" , \"nodeId\" : \"WyJwdWJsaWMiLCAiYmxvZyIsIDFd\" , \"description\" : \"Description of Some Blog\" } } } Collections Each table has top level entry in the Query type for selecting records from that table. Collections return a connection type and can be paginated , filtered , and sorted using the available arguments. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null , \"updatedAt\" timestamp not null ); GraphQL Types QueryType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \"\"\"The root type for querying data\"\"\" type Query { \"\"\"A pagable collection of type `Blog`\"\"\" blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ): BlogConnection } Connection types are the primary interface to returning records from a collection. Connections wrap a result set with some additional metadata. BlogConnection BlogEdge PageInfo Blog BlogOrderBy BlogFilter 1 2 3 4 5 6 7 8 9 10 11 12 type BlogConnection { # Count of all records matching the *filter* criteria totalCount: Int ! # Pagination metadata pageInfo: PageInfo ! # Result set edges: [ BlogEdge !]! } 1 2 3 4 5 6 7 8 9 type BlogEdge { # Unique identifier of the record within the query cursor: String ! # Contents of a record/row in the results set node: Blog } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 type PageInfo { # unique identifier of the first record within the query startCursor: String # unique identifier of the last record within the query endCursor: String # is another page of content available hasNextPage: Boolean ! # is another page of content available hasPreviousPage: Boolean ! } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # A record from the `blog` table type Blog { # globally unique identifier nodeId: ID ! # Value from `id` column id: Int ! # Value from `name` column name: String ! # Value from `description` column description: String # Value from `createdAt` column createdAt: Datetime ! # Value from `updatedAt` column updatedAt: Datetime ! } 1 2 3 4 5 6 7 input BlogOrderBy { id: OrderByDirection name: OrderByDirection description: OrderByDirection createdAt: OrderByDirection updatedAt: OrderByDirection } 1 2 3 4 5 6 7 8 9 10 11 input BlogFilter { nodeId: IDFilter id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } Note The totalCount field is disabled by default because it can be expensive on large tables. To enable it use a comment directive Pagination Paginating forwards and backwards through collections is handled using the first , last , before , and after parameters, following the relay spec . QueryType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type Query { blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor ... truncated ... ): BlogConnection } Metadata relating to the current page of a result set is available on the pageInfo field of the connection type returned from a collection. PageInfo BlogConnection 1 2 3 4 5 6 7 8 9 10 11 12 13 14 type PageInfo { # unique identifier of the first record within the query startCursor: String # unique identifier of the last record within the query endCursor: String # is another page of content available hasNextPage: Boolean ! # is another page of content available hasPreviousPage: Boolean ! } 1 2 3 4 5 6 7 8 9 type BlogConnection { # Pagination metadata pageInfo: PageInfo ! # Result set edges: [ BlogEdge !]! } To paginate forward in the collection, use the first and after arguments. To retrieve the first page, the after argument should be null or absent. Example Query Page 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { blogCollection ( first: 2 , after: null ) { pageInfo { startCursor endCursor hasPreviousPage hasNextPage } edges { cursor node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 }, \"cursor\" : \"WzJd\" } ], \"pageInfo\" : { \"startCursor\" : \"WzFd\" , \"endCursor\" : \"WzJd\" , \"hasNextPage\" : true , \"hasPreviousPage\" : false } } } } To retrieve the next page, provide the cursor value from data.blogCollection.pageInfo.endCursor to the after argument of another query. Query Page 2 1 2 3 4 5 6 7 { blogCollection ( first: 2 , after: \"WzJd\" ) { ... truncated ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 3 }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 }, \"cursor\" : \"WzRd\" } ], \"pageInfo\" : { \"startCursor\" : \"WzNd\" , \"endCursor\" : \"WzRd\" , \"hasNextPage\" : false , \"hasPreviousPage\" : true } } } } once the collection has been fully enumerated, data.blogConnection.pageInfo.hasNextPage returns false. To paginate backwards through a collection, repeat the process substituting first -> last , after -> before , hasNextPage -> hasPreviousPage Filtering To filter the result set, use the filter argument. QueryType 1 2 3 4 5 6 7 8 9 10 11 type Query { blogCollection ( \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter ... truncated ... ): BlogConnection } Where the <Table>Filter type enumerates filterable fields and their associated <Type>Filter . BlogFilter IntFilter StringFilter FilterIs 1 2 3 4 5 6 7 8 9 10 11 input BlogFilter { nodeId: IDFilter id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } 1 2 3 4 5 6 7 8 9 10 11 12 13 \"\"\" Boolean expression comparing fields on type \"Int\" \"\"\" input IntFilter { eq: Int gt: Int gte: Int in: [ Int !] lt: Int lte: Int neq: Int is: FilterIs } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \"\"\" Boolean expression comparing fields on type \"String\" \"\"\" input StringFilter { eq: String gt: String gte: String in: [ String !] lt: String lte: String neq: String is: FilterIs startsWith: String like: String ilike: String regex: String iregex: String } 1 2 3 4 enum FilterIs { NULL NOT_NULL } The following list shows the operators that may be available on <Type>Filter types. Operator Description eq Equal To neq Not Equal To gt Greater Than gte Greater Than Or Equal To in Contained by Value List lt Less Than lte Less Than Or Equal To is Null or Not Null startsWith Starts with prefix like Pattern Match. '%' as wildcard ilike Pattern Match. '%' as wildcard. Case Insensitive regex POSIX Regular Expression Match iregex POSIX Regular Expression Match. Case Insensitive Not all operators are available on every <Type>Filter type. For example, UUIDFilter only supports eq and neq because UUID s are not ordered. Example: simple Query Result 1 2 3 4 5 6 7 8 9 10 11 12 { blogCollection ( filter: { id: { lt: 3 }} , ) { edges { cursor node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 }, \"cursor\" : \"WzJd\" } ] } } } Example: and/or Multiple filters can be combined with and , or and not operators. The and and or operators accept a list of <Type>Filter . and Filter Query and Filter Result or Filter Query or Filter Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { blogCollection ( filter: { and: [ { id: { eq: 1 }} { name: { eq: \"A: Blog 1\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" } ] } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { blogCollection ( filter: { or: [ { id: { eq: 1 }} { name: { eq: \"A: Blog 2\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" } ] } } } Example: not not accepts a single <Type>Filter . not Filter Query not Filter Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection ( filter: { not: { id: { eq: 1 }} } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Example: nested composition The and , or and not operators can be arbitrarily nested inside each other. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { or: [ { id: { eq: 1 } } { id: { eq: 2 } } { and: [{ id: { eq: 3 } , not: { name: { eq: \"A: Blog 2\" } } }] } ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" } ] } } } Example: empty Empty filters are ignored, i.e. they behave as if the operator was not specified at all. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection ( filter: { and: [] , or: [] , not: {} } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Example: implicit and Multiple column filters at the same level will be implicitly combined with boolean and . In the following example the id: {eq: 1} and name: {eq: \"A: Blog 1\"} will be and ed. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { # Equivalent to not: { and: [{id: {eq: 1}}, {name: {eq: \"A: Blog 1\"}}]} not: { id: { eq: 1 } name: { eq: \"A: Blog 1\" } } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } This means that an and filter can be often be simplified. In the following example all queries are equivalent and produce the same result. Original and Query Simplified and Query Even More Simplified Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { and: [ { id: { gt: 0 }} { id: { lt: 2 }} { name: { eq: \"A: Blog 1\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { blogCollection ( filter: { id: { gt: 0 } id: { lt: 2 } name: { eq: \"A: Blog 1\" } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { blogCollection ( filter: { id: { gt: 0 , lt: 2 } name: { eq: \"A: Blog 1\" } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Be aware that the above simplification only works for the and operator. If you try it with an or operator it will behave like an and . Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { # This is really an `and` in `or`'s clothing or: { id: { eq: 1 } name: { eq: \"A: Blog 2\" } } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 { \"data\" : { \"blogCollection\" : { \"edges\" : [] } } } This is because according to the rules of GraphQL list input coercion, if a value passed to an input of list type is not a list, then it is coerced to a list of a single item. So in the above example or: {id: {eq: 1}, name: {eq: \"A: Blog 2}} will be coerced into or: [{id: {eq: 1}, name: {eq: \"A: Blog 2}}] which is equivalent to or: [and: [{id: {eq: 1}}, {name: {eq: \"A: Blog 2}}}] due to implicit and ing. Note Avoid naming your columns and , or or not . If you do, the corresponding filter operator will not be available for use. The and , or and not operators also work with update and delete mutations. Ordering The default order of results is defined by the underlying table's primary key column in ascending order. That default can be overridden by passing an array of <Table>OrderBy to the collection's orderBy argument. QueryType BlogOrderBy OrderByDirection 1 2 3 4 5 6 7 8 9 10 11 type Query { blogCollection ( \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ... truncated ... ): BlogConnection } 1 2 3 4 5 6 7 input BlogOrderBy { id: OrderByDirection name: OrderByDirection description: OrderByDirection createdAt: OrderByDirection updatedAt: OrderByDirection } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \"\"\"Defines a per-field sorting order\"\"\" enum OrderByDirection { \"\"\"Ascending order, nulls first\"\"\" AscNullsFirst \"\"\"Ascending order, nulls last\"\"\" AscNullsLast \"\"\"Descending order, nulls first\"\"\" DescNullsFirst \"\"\"Descending order, nulls last\"\"\" DescNullsLast } Example Query Result 1 2 3 4 5 6 7 8 9 10 11 { blogCollection ( orderBy: [{ id: DescNullsLast }] ) { edges { node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 4 } }, { \"node\" : { \"id\" : 3 } }, { \"node\" : { \"id\" : 2 } }, { \"node\" : { \"id\" : 1 } } ] } } } Note, only one key value pair may be provided to each element of the input array. For example, [{name: AscNullsLast}, {id: AscNullFirst}] is valid. Passing multiple key value pairs in a single element of the input array e.g. [{name: AscNullsLast, id: AscNullFirst}] , is invalid. MutationType The Mutation type is the entrypoint for mutations/edits. Each table has top level entry in the Mutation type for inserting insertInto<Table>Collection , updating update<Table>Collection and deleting deleteFrom<Table>Collection . SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); MutationType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Adds one or more `BlogInsertResponse` records to the collection\"\"\" insertIntoBlogCollection ( \"\"\"Records to add to the Blog collection\"\"\" objects: [ BlogInsertInput !]! ): BlogInsertResponse \"\"\"Updates zero or more records in the collection\"\"\" updateBlogCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogUpdateResponse ! \"\"\"Deletes zero or more records from the collection\"\"\" deleteFromBlogCollection ( \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogDeleteResponse ! } Insert To add records to a collection, use the insertInto<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogInsertInput BlogInsertResponse 1 2 3 4 5 6 7 8 9 10 11 12 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Adds one or more `BlogInsertResponse` records to the collection\"\"\" insertIntoBlogCollection ( \"\"\"Records to add to the Blog collection\"\"\" objects: [ BlogInsertInput !]! ): BlogInsertResponse } 1 2 3 4 5 6 input BlogInsertInput { name: String description: String createdAt: Datetime updatedAt: Datetime } 1 2 3 4 5 6 7 type BlogInsertResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where elements in the objects array are inserted into the underlying table. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { insertIntoBlogCollection ( objects: [ { name: \"foo\" } , { name: \"bar\" } , ] ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"insertIntoBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"foo\" }, { \"id\" : 2 , \"name\" : \"bar\" } ], \"affectedCount\" : 2 } } } Update To update records in a collection, use the update<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogUpdateInput BlogUpdateResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Updates zero or more records in the collection\"\"\" updateBlogCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogUpdateResponse ! } 1 2 3 4 5 6 input BlogUpdateInput { name: String description: String createdAt: Datetime updatedAt: Datetime } 1 2 3 4 5 6 7 8 9 type BlogUpdateResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where the set argument is a key value pair describing the values to update, filter controls which records should be updated, and atMost restricts the maximum number of records that may be impacted. If the number of records impacted by the mutation exceeds the atMost parameter the operation will return an error. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 mutation { updateBlogCollection ( set: { name: \"baz\" } filter: { id: { eq: 1 }} ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"updateBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"baz\" } ], \"affectedCount\" : 1 } } } Delete To remove records from a collection, use the deleteFrom<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogFilter BlogDeleteResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Deletes zero or more records from the collection\"\"\" deleteFromBlogCollection ( \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogDeleteResponse ! } 1 2 3 4 5 6 7 8 9 10 input BlogFilter { id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } 1 2 3 4 5 6 7 type BlogDeleteResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where filter controls which records should be deleted and atMost restricts the maximum number of records that may be deleted. If the number of records impacted by the mutation exceeds the atMost parameter the operation will return an error. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 mutation { deleteFromBlogCollection ( filter: { id: { eq: 1 }} ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"deleteFromBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"baz\" } ], \"affectedCount\" : 1 } } } Concepts nodeId The base GraphQL type for every table with a primary key is automatically assigned a nodeId: ID! field. That value, can be passed to the node entrypoint of the Query type to retrieve its other fields. nodeId may also be used as a caching key. relay support By default relay expects the ID field for types to have the name id . pg_graphql uses nodeId by default to avoid conflicting with user defined id columns. You can configure relay to work with pg_graphql's nodeId field with relay's nodeInterfaceIdField option. More info available here . SQL Setup 1 2 3 4 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); GraphQL Types Blog 1 2 3 4 5 type Blog { nodeId : ID ! # this field id : Int ! name : String ! } Relationships Relationships between collections in the Graph are derived from foreign keys. One-to-Many A foreign key on table A referencing table B defines a one-to-many relationship from table A to table B. SQL Setup 1 2 3 4 5 6 7 8 9 10 11 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); create table \"BlogPost\" ( id serial primary key , \"blogId\" integer not null references \"Blog\" ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ) ); GraphQL Types Blog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 type Blog { # globally unique identifier nodeId : ID ! id : Int ! name : String ! description : String blogPostCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first : Int \"\"\"Query the last `n` records in the collection\"\"\" last : Int \"\"\"Query values in the collection before the provided cursor\"\"\" before : Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after : Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter : BlogPostFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy : [ BlogPostOrderBy ! ] ): BlogPostConnection } Where blogPostCollection exposes the full Query interface to BlogPost s. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection { edges { node { name blogPostCollection { edges { node { id title } } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"name\" : \"pg_graphql blog\" , \"blogPostCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"title\" : \"fIr3t p0sT\" } }, { \"node\" : { \"id\" : 3 , \"title\" : \"graphql with postgres\" } } ] } } } ] } } } Many-to-One A foreign key on table A referencing table B defines a many-to-one relationship from table B to table A. SQL Setup 1 2 3 4 5 6 7 8 9 10 11 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); create table \"BlogPost\" ( id serial primary key , \"blogId\" integer not null references \"Blog\" ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ) ); GraphQL Types BlogPost 1 2 3 4 5 6 7 8 9 type BlogPost { nodeId : ID ! id : Int ! blogId : Int ! title : String ! body : String blog : Blog } Where blog exposes the Blog record associated with the BlogPost . Query Result 1 2 3 4 5 6 7 8 9 10 11 12 { blogPostCollection { edges { node { title blog { name } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"data\" : { \"blogPostCollection\" : { \"edges\" : [ { \"node\" : { \"blog\" : { \"name\" : \"pg_graphql blog\" }, \"title\" : \"fIr3t p0sT\" } }, { \"node\" : { \"blog\" : { \"name\" : \"pg_graphql blog\" }, \"title\" : \"graphql with postgres\" } } ] } } } One-to-One A one-to-one relationship is defined by a foreign key on table A referencing table B where the columns making up the foreign key on table A are unique. SQL Setup 1 2 3 4 5 6 7 8 9 10 create table \"EmailAddress\" ( id serial primary key , address text unique not null ); create table \"Employee\" ( id serial primary key , name text not null , email_address_id int unique references \"EmailAddress\" ( id ) ); GraphQL Types Employee EmailAddress 1 2 3 4 5 6 7 type Employee { nodeId : ID ! id : Int ! name : String ! emailAddressId : Int emailAddress : EmailAddress } 1 2 3 4 5 6 type EmailAddress { nodeId : ID ! id : Int ! address : String ! employee : Employee } Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { employeeCollection { edges { node { name emailAddress { address employee { name } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"data\" : { \"employeeCollection\" : { \"edges\" : [ { \"node\" : { \"name\" : \"Foo Barington\" , \"emailAddress\" : { \"address\" : \"foo@bar.com\" , \"employee\" : { \"name\" : \"Foo Barington\" } } } } ] } } } Custom Scalars Due to differences among the types supported by PostgreSQL, JSON, and GraphQL, pg_graphql adds several new Scalar types to handle PostgreSQL builtins that require special handling. JSON pg_graphql serializes json and jsonb data types as String under the custom scalar name JSON . 1 scalar JSON Example Given the setup SQL GraphQL 1 2 3 4 5 6 7 create table \"User\" ( id bigserial primary key , config jsonb ); insert into \"User\" ( config ) values ( jsonb_build_object ( 'palette' , 'dark-mode' )); 1 2 3 4 5 type User { nodeId : ID ! id : BigInt ! config : JSON } The query 1 2 3 4 5 6 7 8 9 { userCollection { edges { node { config } } } } The returns the following data. Note that config is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"userCollection\" : { \"edges\" : [ { \"node\" : { \"config\" : \"{\\\"palette\\\": \\\"dark-mode\\\"}\" } } ] } } } Use serialized JSON strings when updating or inserting JSON fields via the GraphQL API. JSON does not currently support filtering. BigInt PostgreSQL bigint and bigserial types are 64 bit integers. In contrast, JSON supports 32 bit integers. Since PostgreSQL bigint values may be outside the min/max range allowed by JSON, they are represented in the GraphQL schema as BigInt s and values are serialized as strings. 1 2 3 4 5 6 7 8 9 10 11 12 scalar BigInt input BigIntFilter { eq: BigInt gt: BigInt gte: BigInt in: [ BigInt !] lt: BigInt lte: BigInt neq: BigInt is: FilterIs } Example Given the setup SQL GraphQL 1 2 3 4 5 6 7 create table \"Person\" ( id bigserial primary key , name text ); insert into \"Person\" ( name ) values ( 'J. Bazworth' ); 1 2 3 4 5 type Person { nodeId : ID ! id : BigInt ! name : String } The query 1 2 3 4 5 6 7 8 9 10 { personCollection { edges { node { id name } } } } The returns the following data. Note that id is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : \"1\" , \"name\" : \"Foo Barington\" , } } ] } } } BigFloat PostgreSQL's numeric type supports arbitrary precision floating point values. JSON's float is limited to 64-bit precision. Since a PostgreSQL numeric may require more precision than can be handled by JSON, numeric types are represented in the GraphQL schema as BigFloat and values are serialized as strings. 1 2 3 4 5 6 7 8 9 10 11 12 scalar BigFloat input BigFloatFilter { eq: BigFloat gt: BigFloat gte: BigFloat in: [ BigFloat !] lt: BigFloat lte: BigFloat neq: BigFloat is: FilterIs } Example Given the SQL setup 1 2 3 4 5 6 7 create table \"GeneralLedger\" ( id serial primary key , amount numeric ( 10 , 2 ) ); insert into \"GeneralLedger\" ( amount ) values ( 22 . 15 ); The query 1 2 3 4 5 6 7 8 9 10 { generalLedgerCollection { edges { node { id amount } } } } The returns the following data. Note that amount is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"generalLedgerCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"amount\" : \"22.15\" , } } ] } } } Opaque PostgreSQL's type system is extensible and not all types handle all operations e.g. filtering with like . To account for these, pg_graphql introduces a scalar Opaque type. The Opaque type uses PostgreSQL's to_json method to serialize values. That allows complex or unknown types to be included in the schema by delegating handling to the client. 1 2 3 4 5 6 scalar Opaque input OpaqueFilter { eq: Opaque is: FilterIs }","title":"API"},{"location":"api/#primary-keys-required","text":"Every table must have a primary key for it to be exposed in the GraphQL schema. For example, the following Blog table will be available in the GraphQL schema as blogCollection since it has a primary key named id : 1 2 3 4 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , ); But the following table will not be exposed because it doesn't have a primary key: 1 2 3 4 create table \"Blog\" ( id int , name varchar ( 255 ) not null , );","title":"Primary Keys (Required)"},{"location":"api/#querytype","text":"The Query type is the entrypoint for all read access into the graph.","title":"QueryType"},{"location":"api/#node","text":"The node interface allows for retrieving records that are uniquely identifiable by a globally unique nodeId: ID! field. For more information about nodeId, see nodeId . SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null , \"updatedAt\" timestamp not null ); GraphQL Types QueryType 1 2 3 4 5 6 7 \"\"\"The root type for querying data\"\"\" type Query { \"\"\"Retrieve a record by its `ID`\"\"\" node ( nodeId: ID !): Node } To query the node interface effectively, use inline fragments to specify which fields to return for each type. Example Query Response 1 2 3 4 5 6 7 8 9 10 11 12 { node ( nodeId: \"WyJwdWJsaWMiLCAiYmxvZyIsIDFd\" ) { nodeId # Inline fragment for `Blog` type ... on Blog { name description } } } 1 2 3 4 5 6 7 8 9 { \"data\" : { \"node\" : { \"name\" : \"Some Blog\" , \"nodeId\" : \"WyJwdWJsaWMiLCAiYmxvZyIsIDFd\" , \"description\" : \"Description of Some Blog\" } } }","title":"Node"},{"location":"api/#collections","text":"Each table has top level entry in the Query type for selecting records from that table. Collections return a connection type and can be paginated , filtered , and sorted using the available arguments. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null , \"updatedAt\" timestamp not null ); GraphQL Types QueryType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \"\"\"The root type for querying data\"\"\" type Query { \"\"\"A pagable collection of type `Blog`\"\"\" blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ): BlogConnection } Connection types are the primary interface to returning records from a collection. Connections wrap a result set with some additional metadata. BlogConnection BlogEdge PageInfo Blog BlogOrderBy BlogFilter 1 2 3 4 5 6 7 8 9 10 11 12 type BlogConnection { # Count of all records matching the *filter* criteria totalCount: Int ! # Pagination metadata pageInfo: PageInfo ! # Result set edges: [ BlogEdge !]! } 1 2 3 4 5 6 7 8 9 type BlogEdge { # Unique identifier of the record within the query cursor: String ! # Contents of a record/row in the results set node: Blog } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 type PageInfo { # unique identifier of the first record within the query startCursor: String # unique identifier of the last record within the query endCursor: String # is another page of content available hasNextPage: Boolean ! # is another page of content available hasPreviousPage: Boolean ! } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # A record from the `blog` table type Blog { # globally unique identifier nodeId: ID ! # Value from `id` column id: Int ! # Value from `name` column name: String ! # Value from `description` column description: String # Value from `createdAt` column createdAt: Datetime ! # Value from `updatedAt` column updatedAt: Datetime ! } 1 2 3 4 5 6 7 input BlogOrderBy { id: OrderByDirection name: OrderByDirection description: OrderByDirection createdAt: OrderByDirection updatedAt: OrderByDirection } 1 2 3 4 5 6 7 8 9 10 11 input BlogFilter { nodeId: IDFilter id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } Note The totalCount field is disabled by default because it can be expensive on large tables. To enable it use a comment directive","title":"Collections"},{"location":"api/#pagination","text":"Paginating forwards and backwards through collections is handled using the first , last , before , and after parameters, following the relay spec . QueryType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type Query { blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor ... truncated ... ): BlogConnection } Metadata relating to the current page of a result set is available on the pageInfo field of the connection type returned from a collection. PageInfo BlogConnection 1 2 3 4 5 6 7 8 9 10 11 12 13 14 type PageInfo { # unique identifier of the first record within the query startCursor: String # unique identifier of the last record within the query endCursor: String # is another page of content available hasNextPage: Boolean ! # is another page of content available hasPreviousPage: Boolean ! } 1 2 3 4 5 6 7 8 9 type BlogConnection { # Pagination metadata pageInfo: PageInfo ! # Result set edges: [ BlogEdge !]! } To paginate forward in the collection, use the first and after arguments. To retrieve the first page, the after argument should be null or absent. Example Query Page 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { blogCollection ( first: 2 , after: null ) { pageInfo { startCursor endCursor hasPreviousPage hasNextPage } edges { cursor node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 }, \"cursor\" : \"WzJd\" } ], \"pageInfo\" : { \"startCursor\" : \"WzFd\" , \"endCursor\" : \"WzJd\" , \"hasNextPage\" : true , \"hasPreviousPage\" : false } } } } To retrieve the next page, provide the cursor value from data.blogCollection.pageInfo.endCursor to the after argument of another query. Query Page 2 1 2 3 4 5 6 7 { blogCollection ( first: 2 , after: \"WzJd\" ) { ... truncated ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 3 }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 }, \"cursor\" : \"WzRd\" } ], \"pageInfo\" : { \"startCursor\" : \"WzNd\" , \"endCursor\" : \"WzRd\" , \"hasNextPage\" : false , \"hasPreviousPage\" : true } } } } once the collection has been fully enumerated, data.blogConnection.pageInfo.hasNextPage returns false. To paginate backwards through a collection, repeat the process substituting first -> last , after -> before , hasNextPage -> hasPreviousPage","title":"Pagination"},{"location":"api/#filtering","text":"To filter the result set, use the filter argument. QueryType 1 2 3 4 5 6 7 8 9 10 11 type Query { blogCollection ( \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter ... truncated ... ): BlogConnection } Where the <Table>Filter type enumerates filterable fields and their associated <Type>Filter . BlogFilter IntFilter StringFilter FilterIs 1 2 3 4 5 6 7 8 9 10 11 input BlogFilter { nodeId: IDFilter id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } 1 2 3 4 5 6 7 8 9 10 11 12 13 \"\"\" Boolean expression comparing fields on type \"Int\" \"\"\" input IntFilter { eq: Int gt: Int gte: Int in: [ Int !] lt: Int lte: Int neq: Int is: FilterIs } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \"\"\" Boolean expression comparing fields on type \"String\" \"\"\" input StringFilter { eq: String gt: String gte: String in: [ String !] lt: String lte: String neq: String is: FilterIs startsWith: String like: String ilike: String regex: String iregex: String } 1 2 3 4 enum FilterIs { NULL NOT_NULL } The following list shows the operators that may be available on <Type>Filter types. Operator Description eq Equal To neq Not Equal To gt Greater Than gte Greater Than Or Equal To in Contained by Value List lt Less Than lte Less Than Or Equal To is Null or Not Null startsWith Starts with prefix like Pattern Match. '%' as wildcard ilike Pattern Match. '%' as wildcard. Case Insensitive regex POSIX Regular Expression Match iregex POSIX Regular Expression Match. Case Insensitive Not all operators are available on every <Type>Filter type. For example, UUIDFilter only supports eq and neq because UUID s are not ordered. Example: simple Query Result 1 2 3 4 5 6 7 8 9 10 11 12 { blogCollection ( filter: { id: { lt: 3 }} , ) { edges { cursor node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 }, \"cursor\" : \"WzJd\" } ] } } } Example: and/or Multiple filters can be combined with and , or and not operators. The and and or operators accept a list of <Type>Filter . and Filter Query and Filter Result or Filter Query or Filter Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { blogCollection ( filter: { and: [ { id: { eq: 1 }} { name: { eq: \"A: Blog 1\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" } ] } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { blogCollection ( filter: { or: [ { id: { eq: 1 }} { name: { eq: \"A: Blog 2\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" } ] } } } Example: not not accepts a single <Type>Filter . not Filter Query not Filter Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection ( filter: { not: { id: { eq: 1 }} } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Example: nested composition The and , or and not operators can be arbitrarily nested inside each other. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { or: [ { id: { eq: 1 } } { id: { eq: 2 } } { and: [{ id: { eq: 3 } , not: { name: { eq: \"A: Blog 2\" } } }] } ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" } ] } } } Example: empty Empty filters are ignored, i.e. they behave as if the operator was not specified at all. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection ( filter: { and: [] , or: [] , not: {} } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"A: Blog 1\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc1\" }, \"cursor\" : \"WzFd\" }, { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Example: implicit and Multiple column filters at the same level will be implicitly combined with boolean and . In the following example the id: {eq: 1} and name: {eq: \"A: Blog 1\"} will be and ed. Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { # Equivalent to not: { and: [{id: {eq: 1}}, {name: {eq: \"A: Blog 1\"}}]} not: { id: { eq: 1 } name: { eq: \"A: Blog 1\" } } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } This means that an and filter can be often be simplified. In the following example all queries are equivalent and produce the same result. Original and Query Simplified and Query Even More Simplified Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { and: [ { id: { gt: 0 }} { id: { lt: 2 }} { name: { eq: \"A: Blog 1\" }} ] } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { blogCollection ( filter: { id: { gt: 0 } id: { lt: 2 } name: { eq: \"A: Blog 1\" } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { blogCollection ( filter: { id: { gt: 0 , lt: 2 } name: { eq: \"A: Blog 1\" } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"name\" : \"A: Blog 2\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc2\" }, \"cursor\" : \"WzJd\" }, { \"node\" : { \"id\" : 3 , \"name\" : \"A: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"a desc3\" }, \"cursor\" : \"WzNd\" }, { \"node\" : { \"id\" : 4 , \"name\" : \"B: Blog 3\" , \"createdAt\" : \"2023-07-24T04:01:09.882781\" , \"description\" : \"b desc1\" }, \"cursor\" : \"WzRd\" } ] } } } Be aware that the above simplification only works for the and operator. If you try it with an or operator it will behave like an and . Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { blogCollection ( filter: { # This is really an `and` in `or`'s clothing or: { id: { eq: 1 } name: { eq: \"A: Blog 2\" } } } ) { edges { cursor node { id name description createdAt } } } } 1 2 3 4 5 6 7 { \"data\" : { \"blogCollection\" : { \"edges\" : [] } } } This is because according to the rules of GraphQL list input coercion, if a value passed to an input of list type is not a list, then it is coerced to a list of a single item. So in the above example or: {id: {eq: 1}, name: {eq: \"A: Blog 2}} will be coerced into or: [{id: {eq: 1}, name: {eq: \"A: Blog 2}}] which is equivalent to or: [and: [{id: {eq: 1}}, {name: {eq: \"A: Blog 2}}}] due to implicit and ing. Note Avoid naming your columns and , or or not . If you do, the corresponding filter operator will not be available for use. The and , or and not operators also work with update and delete mutations.","title":"Filtering"},{"location":"api/#ordering","text":"The default order of results is defined by the underlying table's primary key column in ascending order. That default can be overridden by passing an array of <Table>OrderBy to the collection's orderBy argument. QueryType BlogOrderBy OrderByDirection 1 2 3 4 5 6 7 8 9 10 11 type Query { blogCollection ( \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ... truncated ... ): BlogConnection } 1 2 3 4 5 6 7 input BlogOrderBy { id: OrderByDirection name: OrderByDirection description: OrderByDirection createdAt: OrderByDirection updatedAt: OrderByDirection } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \"\"\"Defines a per-field sorting order\"\"\" enum OrderByDirection { \"\"\"Ascending order, nulls first\"\"\" AscNullsFirst \"\"\"Ascending order, nulls last\"\"\" AscNullsLast \"\"\"Descending order, nulls first\"\"\" DescNullsFirst \"\"\"Descending order, nulls last\"\"\" DescNullsLast } Example Query Result 1 2 3 4 5 6 7 8 9 10 11 { blogCollection ( orderBy: [{ id: DescNullsLast }] ) { edges { node { id } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 4 } }, { \"node\" : { \"id\" : 3 } }, { \"node\" : { \"id\" : 2 } }, { \"node\" : { \"id\" : 1 } } ] } } } Note, only one key value pair may be provided to each element of the input array. For example, [{name: AscNullsLast}, {id: AscNullFirst}] is valid. Passing multiple key value pairs in a single element of the input array e.g. [{name: AscNullsLast, id: AscNullFirst}] , is invalid.","title":"Ordering"},{"location":"api/#mutationtype","text":"The Mutation type is the entrypoint for mutations/edits. Each table has top level entry in the Mutation type for inserting insertInto<Table>Collection , updating update<Table>Collection and deleting deleteFrom<Table>Collection . SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); MutationType 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Adds one or more `BlogInsertResponse` records to the collection\"\"\" insertIntoBlogCollection ( \"\"\"Records to add to the Blog collection\"\"\" objects: [ BlogInsertInput !]! ): BlogInsertResponse \"\"\"Updates zero or more records in the collection\"\"\" updateBlogCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogUpdateResponse ! \"\"\"Deletes zero or more records from the collection\"\"\" deleteFromBlogCollection ( \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogDeleteResponse ! }","title":"MutationType"},{"location":"api/#insert","text":"To add records to a collection, use the insertInto<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogInsertInput BlogInsertResponse 1 2 3 4 5 6 7 8 9 10 11 12 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Adds one or more `BlogInsertResponse` records to the collection\"\"\" insertIntoBlogCollection ( \"\"\"Records to add to the Blog collection\"\"\" objects: [ BlogInsertInput !]! ): BlogInsertResponse } 1 2 3 4 5 6 input BlogInsertInput { name: String description: String createdAt: Datetime updatedAt: Datetime } 1 2 3 4 5 6 7 type BlogInsertResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where elements in the objects array are inserted into the underlying table. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mutation { insertIntoBlogCollection ( objects: [ { name: \"foo\" } , { name: \"bar\" } , ] ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"insertIntoBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"foo\" }, { \"id\" : 2 , \"name\" : \"bar\" } ], \"affectedCount\" : 2 } } }","title":"Insert"},{"location":"api/#update","text":"To update records in a collection, use the update<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogUpdateInput BlogUpdateResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Updates zero or more records in the collection\"\"\" updateBlogCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogUpdateResponse ! } 1 2 3 4 5 6 input BlogUpdateInput { name: String description: String createdAt: Datetime updatedAt: Datetime } 1 2 3 4 5 6 7 8 9 type BlogUpdateResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where the set argument is a key value pair describing the values to update, filter controls which records should be updated, and atMost restricts the maximum number of records that may be impacted. If the number of records impacted by the mutation exceeds the atMost parameter the operation will return an error. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 mutation { updateBlogCollection ( set: { name: \"baz\" } filter: { id: { eq: 1 }} ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"updateBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"baz\" } ], \"affectedCount\" : 1 } } }","title":"Update"},{"location":"api/#delete","text":"To remove records from a collection, use the deleteFrom<Table>Collection field on the Mutation type. SQL Setup 1 2 3 4 5 6 7 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null , description varchar ( 255 ), \"createdAt\" timestamp not null default now (), \"updatedAt\" timestamp ); GraphQL Types MutationType BlogFilter BlogDeleteResponse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Deletes zero or more records from the collection\"\"\" deleteFromBlogCollection ( \"\"\"Restricts the mutation's impact to records matching the critera\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogDeleteResponse ! } 1 2 3 4 5 6 7 8 9 10 input BlogFilter { id: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter updatedAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } 1 2 3 4 5 6 7 type BlogDeleteResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } Where filter controls which records should be deleted and atMost restricts the maximum number of records that may be deleted. If the number of records impacted by the mutation exceeds the atMost parameter the operation will return an error. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 mutation { deleteFromBlogCollection ( filter: { id: { eq: 1 }} ) { affectedCount records { id name } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"deleteFromBlogCollection\" : { \"records\" : [ { \"id\" : 1 , \"name\" : \"baz\" } ], \"affectedCount\" : 1 } } }","title":"Delete"},{"location":"api/#concepts","text":"","title":"Concepts"},{"location":"api/#nodeid","text":"The base GraphQL type for every table with a primary key is automatically assigned a nodeId: ID! field. That value, can be passed to the node entrypoint of the Query type to retrieve its other fields. nodeId may also be used as a caching key. relay support By default relay expects the ID field for types to have the name id . pg_graphql uses nodeId by default to avoid conflicting with user defined id columns. You can configure relay to work with pg_graphql's nodeId field with relay's nodeInterfaceIdField option. More info available here . SQL Setup 1 2 3 4 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); GraphQL Types Blog 1 2 3 4 5 type Blog { nodeId : ID ! # this field id : Int ! name : String ! }","title":"nodeId"},{"location":"api/#relationships","text":"Relationships between collections in the Graph are derived from foreign keys.","title":"Relationships"},{"location":"api/#one-to-many","text":"A foreign key on table A referencing table B defines a one-to-many relationship from table A to table B. SQL Setup 1 2 3 4 5 6 7 8 9 10 11 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); create table \"BlogPost\" ( id serial primary key , \"blogId\" integer not null references \"Blog\" ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ) ); GraphQL Types Blog 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 type Blog { # globally unique identifier nodeId : ID ! id : Int ! name : String ! description : String blogPostCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first : Int \"\"\"Query the last `n` records in the collection\"\"\" last : Int \"\"\"Query values in the collection before the provided cursor\"\"\" before : Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after : Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter : BlogPostFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy : [ BlogPostOrderBy ! ] ): BlogPostConnection } Where blogPostCollection exposes the full Query interface to BlogPost s. Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { blogCollection { edges { node { name blogPostCollection { edges { node { id title } } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 { \"data\" : { \"blogCollection\" : { \"edges\" : [ { \"node\" : { \"name\" : \"pg_graphql blog\" , \"blogPostCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 2 , \"title\" : \"fIr3t p0sT\" } }, { \"node\" : { \"id\" : 3 , \"title\" : \"graphql with postgres\" } } ] } } } ] } } }","title":"One-to-Many"},{"location":"api/#many-to-one","text":"A foreign key on table A referencing table B defines a many-to-one relationship from table B to table A. SQL Setup 1 2 3 4 5 6 7 8 9 10 11 create table \"Blog\" ( id serial primary key , name varchar ( 255 ) not null ); create table \"BlogPost\" ( id serial primary key , \"blogId\" integer not null references \"Blog\" ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ) ); GraphQL Types BlogPost 1 2 3 4 5 6 7 8 9 type BlogPost { nodeId : ID ! id : Int ! blogId : Int ! title : String ! body : String blog : Blog } Where blog exposes the Blog record associated with the BlogPost . Query Result 1 2 3 4 5 6 7 8 9 10 11 12 { blogPostCollection { edges { node { title blog { name } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"data\" : { \"blogPostCollection\" : { \"edges\" : [ { \"node\" : { \"blog\" : { \"name\" : \"pg_graphql blog\" }, \"title\" : \"fIr3t p0sT\" } }, { \"node\" : { \"blog\" : { \"name\" : \"pg_graphql blog\" }, \"title\" : \"graphql with postgres\" } } ] } } }","title":"Many-to-One"},{"location":"api/#one-to-one","text":"A one-to-one relationship is defined by a foreign key on table A referencing table B where the columns making up the foreign key on table A are unique. SQL Setup 1 2 3 4 5 6 7 8 9 10 create table \"EmailAddress\" ( id serial primary key , address text unique not null ); create table \"Employee\" ( id serial primary key , name text not null , email_address_id int unique references \"EmailAddress\" ( id ) ); GraphQL Types Employee EmailAddress 1 2 3 4 5 6 7 type Employee { nodeId : ID ! id : Int ! name : String ! emailAddressId : Int emailAddress : EmailAddress } 1 2 3 4 5 6 type EmailAddress { nodeId : ID ! id : Int ! address : String ! employee : Employee } Example Query Result 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { employeeCollection { edges { node { name emailAddress { address employee { name } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"data\" : { \"employeeCollection\" : { \"edges\" : [ { \"node\" : { \"name\" : \"Foo Barington\" , \"emailAddress\" : { \"address\" : \"foo@bar.com\" , \"employee\" : { \"name\" : \"Foo Barington\" } } } } ] } } }","title":"One-to-One"},{"location":"api/#custom-scalars","text":"Due to differences among the types supported by PostgreSQL, JSON, and GraphQL, pg_graphql adds several new Scalar types to handle PostgreSQL builtins that require special handling.","title":"Custom Scalars"},{"location":"api/#json","text":"pg_graphql serializes json and jsonb data types as String under the custom scalar name JSON . 1 scalar JSON Example Given the setup SQL GraphQL 1 2 3 4 5 6 7 create table \"User\" ( id bigserial primary key , config jsonb ); insert into \"User\" ( config ) values ( jsonb_build_object ( 'palette' , 'dark-mode' )); 1 2 3 4 5 type User { nodeId : ID ! id : BigInt ! config : JSON } The query 1 2 3 4 5 6 7 8 9 { userCollection { edges { node { config } } } } The returns the following data. Note that config is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 { \"data\" : { \"userCollection\" : { \"edges\" : [ { \"node\" : { \"config\" : \"{\\\"palette\\\": \\\"dark-mode\\\"}\" } } ] } } } Use serialized JSON strings when updating or inserting JSON fields via the GraphQL API. JSON does not currently support filtering.","title":"JSON"},{"location":"api/#bigint","text":"PostgreSQL bigint and bigserial types are 64 bit integers. In contrast, JSON supports 32 bit integers. Since PostgreSQL bigint values may be outside the min/max range allowed by JSON, they are represented in the GraphQL schema as BigInt s and values are serialized as strings. 1 2 3 4 5 6 7 8 9 10 11 12 scalar BigInt input BigIntFilter { eq: BigInt gt: BigInt gte: BigInt in: [ BigInt !] lt: BigInt lte: BigInt neq: BigInt is: FilterIs } Example Given the setup SQL GraphQL 1 2 3 4 5 6 7 create table \"Person\" ( id bigserial primary key , name text ); insert into \"Person\" ( name ) values ( 'J. Bazworth' ); 1 2 3 4 5 type Person { nodeId : ID ! id : BigInt ! name : String } The query 1 2 3 4 5 6 7 8 9 10 { personCollection { edges { node { id name } } } } The returns the following data. Note that id is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : \"1\" , \"name\" : \"Foo Barington\" , } } ] } } }","title":"BigInt"},{"location":"api/#bigfloat","text":"PostgreSQL's numeric type supports arbitrary precision floating point values. JSON's float is limited to 64-bit precision. Since a PostgreSQL numeric may require more precision than can be handled by JSON, numeric types are represented in the GraphQL schema as BigFloat and values are serialized as strings. 1 2 3 4 5 6 7 8 9 10 11 12 scalar BigFloat input BigFloatFilter { eq: BigFloat gt: BigFloat gte: BigFloat in: [ BigFloat !] lt: BigFloat lte: BigFloat neq: BigFloat is: FilterIs } Example Given the SQL setup 1 2 3 4 5 6 7 create table \"GeneralLedger\" ( id serial primary key , amount numeric ( 10 , 2 ) ); insert into \"GeneralLedger\" ( amount ) values ( 22 . 15 ); The query 1 2 3 4 5 6 7 8 9 10 { generalLedgerCollection { edges { node { id amount } } } } The returns the following data. Note that amount is serialized as a string 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"generalLedgerCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"amount\" : \"22.15\" , } } ] } } }","title":"BigFloat"},{"location":"api/#opaque","text":"PostgreSQL's type system is extensible and not all types handle all operations e.g. filtering with like . To account for these, pg_graphql introduces a scalar Opaque type. The Opaque type uses PostgreSQL's to_json method to serialize values. That allows complex or unknown types to be included in the schema by delegating handling to the client. 1 2 3 4 5 6 scalar Opaque input OpaqueFilter { eq: Opaque is: FilterIs }","title":"Opaque"},{"location":"changelog/","text":"1.0.0 Initial release 1.0.1 feature: Add support for Postgres 15 1.0.2 bugfix: Correct inconsistent treatment of null literals 1.1.0 feature: Add support for Views, Materialized Views, and Foreign Tables feature: Add support for filtering on is null and is not null feature: User configurable page size bugfix: Remove requirement for insert permission on every column for inserts to succeed bugfix: hasNextPage and hasPreviousPage during reverse pagination were backwards 1.2.0 feature: String type filters support ilike , like , startsWith feature: Support for @skip and @include directives feature: Custom descriptions via comment directive @graphql({\"description\": ...}) bugfix: Unknown types are represented in GraphQL schema as Opaque rather than String bugfix: PostgreSQL type modifiers, e.g. char(n), no longer truncate excess text bugfix: Creating a new enum variant between existing variants no longer errors 1.2.1 feature: String type filters support regex , iregex feature: computed relationships via functions returning setof bugfix: function based computed columns with same name no longer error 1.2.2 feature: reproducible builds 1.2.3 bugfix: enums not on the roles search_path are excluded from introspection bugfix: remove duplicate Enum registration bugfix: foreign keys on non-null columns produce non-null GraphQL relationships 1.3.0 feature: rename enum variants with comment directive @graphql({\"mappings\": \"sql-value\": \"graphql_value\"\"}) bugfix: query with more than 50 fields fails bugfix: @skip and @include directives missing from introspection schema feature: Support for and , or and not operators in filters bugfix: queries failed to run if the database was in read-only replica mode 1.4.0 feature: citext type represented as a GraphQL String feature: Support for Postgres 16 feature: Support for user defined functions 1.4.1 feature: Support for user defined functions with default arguments bugfix: Trigger functions excluded from API 1.4.2 bugfix: UDF call returned null if the row returned by the function had any null column master bugfix: make non-default args non-null in UDFs bugfix: default value of a string type argument in a UDF was wrapped in single quotes feature: add support for array types in UDFs","title":"Changelog"},{"location":"changelog/#100","text":"Initial release","title":"1.0.0"},{"location":"changelog/#101","text":"feature: Add support for Postgres 15","title":"1.0.1"},{"location":"changelog/#102","text":"bugfix: Correct inconsistent treatment of null literals","title":"1.0.2"},{"location":"changelog/#110","text":"feature: Add support for Views, Materialized Views, and Foreign Tables feature: Add support for filtering on is null and is not null feature: User configurable page size bugfix: Remove requirement for insert permission on every column for inserts to succeed bugfix: hasNextPage and hasPreviousPage during reverse pagination were backwards","title":"1.1.0"},{"location":"changelog/#120","text":"feature: String type filters support ilike , like , startsWith feature: Support for @skip and @include directives feature: Custom descriptions via comment directive @graphql({\"description\": ...}) bugfix: Unknown types are represented in GraphQL schema as Opaque rather than String bugfix: PostgreSQL type modifiers, e.g. char(n), no longer truncate excess text bugfix: Creating a new enum variant between existing variants no longer errors","title":"1.2.0"},{"location":"changelog/#121","text":"feature: String type filters support regex , iregex feature: computed relationships via functions returning setof bugfix: function based computed columns with same name no longer error","title":"1.2.1"},{"location":"changelog/#122","text":"feature: reproducible builds","title":"1.2.2"},{"location":"changelog/#123","text":"bugfix: enums not on the roles search_path are excluded from introspection bugfix: remove duplicate Enum registration bugfix: foreign keys on non-null columns produce non-null GraphQL relationships","title":"1.2.3"},{"location":"changelog/#130","text":"feature: rename enum variants with comment directive @graphql({\"mappings\": \"sql-value\": \"graphql_value\"\"}) bugfix: query with more than 50 fields fails bugfix: @skip and @include directives missing from introspection schema feature: Support for and , or and not operators in filters bugfix: queries failed to run if the database was in read-only replica mode","title":"1.3.0"},{"location":"changelog/#140","text":"feature: citext type represented as a GraphQL String feature: Support for Postgres 16 feature: Support for user defined functions","title":"1.4.0"},{"location":"changelog/#141","text":"feature: Support for user defined functions with default arguments bugfix: Trigger functions excluded from API","title":"1.4.1"},{"location":"changelog/#142","text":"bugfix: UDF call returned null if the row returned by the function had any null column","title":"1.4.2"},{"location":"changelog/#master","text":"bugfix: make non-default args non-null in UDFs bugfix: default value of a string type argument in a UDF was wrapped in single quotes feature: add support for array types in UDFs","title":"master"},{"location":"computed_fields/","text":"Computed Values PostgreSQL Builtin (Preferred) PostgreSQL has a builtin method for adding generated columns to tables. Generated columns are reflected identically to non-generated columns. This is the recommended approach to adding computed fields when your computation meets the restrictions. Namely: expression must be immutable expression may only reference the current row For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 begin ; comment on schema public is '@graphql({\"inflect_names\": true})' ; create table public . account ( id serial primary key , first_name varchar ( 255 ) not null , last_name varchar ( 255 ) not null , -- Computed Column full_name text generated always as ( first_name || ' ' || last_name ) stored ); insert into public . account ( first_name , last_name ) values ( 'Foo' , 'Fooington' ); select jsonb_pretty ( graphql . resolve ( $$ { accountCollection { edges { node { id firstName lastName fullName } } } } $$ ) ); jsonb_pretty ------------------------------------------------------ { + \"data\" : { + \"accountCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : 1 , + \"fullName\" : \"Foo Fooington\" , + \"lastName\" : \"Fooington\" , + \"firstName\" : \"Foo\" + } + } + ] + } + } + } ( 1 row ) rollback ; Extending Types with Functions For arbitrary computations that do not meet the requirements for generated columns , a table's reflected GraphQL type can be extended by creating a function that: accepts a single argument of the table's tuple type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 begin ; comment on schema public is '@graphql({\"inflect_names\": true})' ; create table public . account ( id serial primary key , first_name varchar ( 255 ) not null , last_name varchar ( 255 ) not null , parent_id int references account ( id ) ); -- Extend with function create function public . _full_name ( rec public . account ) returns text immutable strict language sql as $$ select format ( '%s %s' , rec . first_name , rec . last_name ) $$ ; insert into public . account ( first_name , last_name , parent_id ) values ( 'Foo' , 'Fooington' , 1 ); select jsonb_pretty ( graphql . resolve ( $$ { accountCollection { edges { node { id firstName lastName fullName parent { fullName } } } } } $$ ) ); jsonb_pretty --------------------------------------------------------- { + \"data\" : { + \"accountCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : 1 , + \"parent\" : { + \"fullName\" : \"Foo Fooington\" + } , + \"fullName\" : \"Foo Fooington\" , + \"lastName\" : \"Fooington\" , + \"firstName\" : \"Foo\" + } + } + ] + } + } + } ( 1 row ) rollback ; If the function is written in SQL, its volatility can impact freshness of data returned in mutations: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 begin ; -- A computed field function written in SQL and marked stable might return stale results. -- Directly from the postgres docs(https://www.postgresql.org/docs/current/xfunc-volatility.html): --For functions written in SQL or in any of the standard procedural languages, --there is a second important property determined by the volatility category, --namely the visibility of any data changes that have been made by the SQL --command that is calling the function. A VOLATILE function will see such --changes, a STABLE or IMMUTABLE function will not. This behavior is --implemented using the snapshotting behavior of MVCC (see Chapter 13): STABLE --and IMMUTABLE functions use a snapshot established as of the start of the --calling query, whereas VOLATILE functions obtain a fresh snapshot at the --start of each query they execute. --The solution is to mark these functions as volatile create table parent ( id uuid primary key default gen_random_uuid (), count int2 ); create table child ( id uuid primary key default gen_random_uuid (), parent_id uuid references parent not null , count int2 ); -- note that the function is marked stable and in written in sql create or replace function _count ( rec parent ) returns smallint stable language sql as $$ select sum ( count ) from child where parent_id = rec . id $$ ; insert into parent ( id , count ) values ( '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 1 ); insert into child ( id , parent_id , count ) values ( '57738181-3d0f-45ad-96dd-3ba799b2d21d' , '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 2 ), ( 'cb5993ff-e693-49cd-9114-a6510707e628' , '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 3 ); select jsonb_pretty ( graphql . resolve ( $$ query ParentQuery { parentCollection { edges { node { id count childCollection { edges { node { count } } } } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"parentCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 5 , + \"childCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"count\" : 2 + } + } , + { + \"node\" : { + \"count\" : 3 + } + } + ] + } + } + } + ] + } + } + } ( 1 row ) -- since _count is stable, the value returned in parent.count field will be stale -- i.e. parent.count is still 5 instead of (3 + 5) = 8 select jsonb_pretty ( graphql . resolve ( $$ mutation ChildMutation { updateChildCollection ( filter : { id : { eq : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" } } set : { count : 5 } ) { records { id count parent { id count } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"updateChildCollection\" : { + \"records\" : [ + { + \"id\" : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" , + \"count\" : 5 , + \"parent\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 5 + } + } + ] + } + } + } ( 1 row ) -- note that the function is marked volatile create or replace function _count ( rec parent ) returns smallint volatile language sql as $$ select sum ( count ) from child where parent_id = rec . id $$ ; -- since _count is volatile, the value returned in parent.count field will be fresh -- i.e. parent.count is correctly at (3 + 7) 10 select jsonb_pretty ( graphql . resolve ( $$ mutation ChildMutation { updateChildCollection ( filter : { id : { eq : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" } } set : { count : 7 } ) { records { id count parent { id count } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"updateChildCollection\" : { + \"records\" : [ + { + \"id\" : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" , + \"count\" : 7 , + \"parent\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 10 + } + } + ] + } + } + } ( 1 row ) rollback ; Computed Relationships Computed relations can be helpful to express relationships: between entities that don't support foreign keys too complex to be expressed via a foreign key If the relationship is simple, but involves an entity that does not support foreign keys e.g. Foreign Data Wrappers / Views, defining a comment directive is the easiest solution. See the view doc for a complete example. Note that for entities that do not support a primary key, like views, you must define one using a comment directive to use them in a computed relationship. Alternatively, if the relationship is complex, or you need compatibility with PostgREST, you can define a relationship using set returning functions. To-One To One relationships can be defined using a function that returns setof <entity> rows 1 For example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 create table \"Person\" ( id int primary key , name text ); create table \"Address\" ( id int primary key , \"isPrimary\" bool not null default false , \"personId\" int references \"Person\" ( id ), address text ); -- Example computed relation create function \"primaryAddress\" ( \"Person\" ) returns setof \"Address\" rows 1 language sql as $$ select addr from \"Address\" addr where $ 1 . id = addr . \"personId\" and addr . \"isPrimary\" limit 1 $$ ; insert into \"Person\" ( id , name ) values ( 1 , 'Foo Barington' ); insert into \"Address\" ( id , \"isPrimary\" , \"personId\" , address ) values ( 4 , true , 1 , '1 Main St.' ); results in the GraphQL type Person 1 2 3 4 5 6 type Person implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! ... primaryAddress: Address } and can be queried like a natively enforced relationship Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { personCollection { edges { node { id name primaryAddress { address } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"Foo Barington\" , \"primaryAddress\" : { \"address\" : \"1 Main St.\" } } } ] } } } To-Many To-many relationships can be defined using a function that returns a setof <entity> For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 create table \"Person\" ( id int primary key , name text ); create table \"Address\" ( id int primary key , address text ); create table \"PersonAtAddress\" ( id int primary key , \"personId\" int not null , \"addressId\" int not null ); -- Computed relation to bypass \"PersonAtAddress\" table for cleaner API create function \"addresses\" ( \"Person\" ) returns setof \"Address\" language sql as $$ select addr from \"PersonAtAddress\" pa join \"Address\" addr on pa . \"addressId\" = \"addr\" . id where pa . \"personId\" = $ 1 . id $$ ; insert into \"Person\" ( id , name ) values ( 1 , 'Foo Barington' ); insert into \"Address\" ( id , address ) values ( 4 , '1 Main St.' ); insert into \"PersonAtAddress\" ( id , \"personId\" , \"addressId\" ) values ( 2 , 1 , 4 ); results in the GraphQL type Person 1 2 3 4 5 6 7 8 9 10 11 12 13 type Person implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! ... addresses ( first: Int last: Int before: Cursor after: Cursor filter: AddressFilter orderBy: [ AddressOrderBy !] ): AddressConnection } and can be queried like a natively enforced relationship Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { personCollection { edges { node { id name addresses { edges { node { id address } } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"Foo Barington\" , \"addresses\" : { \"edges\" : [ { \"node\" : { \"id\" : 4 , \"address\" : \"1 Main St.\" } } ] } } } ] } } }","title":"Computed Fields"},{"location":"computed_fields/#computed-values","text":"","title":"Computed Values"},{"location":"computed_fields/#postgresql-builtin-preferred","text":"PostgreSQL has a builtin method for adding generated columns to tables. Generated columns are reflected identically to non-generated columns. This is the recommended approach to adding computed fields when your computation meets the restrictions. Namely: expression must be immutable expression may only reference the current row For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 begin ; comment on schema public is '@graphql({\"inflect_names\": true})' ; create table public . account ( id serial primary key , first_name varchar ( 255 ) not null , last_name varchar ( 255 ) not null , -- Computed Column full_name text generated always as ( first_name || ' ' || last_name ) stored ); insert into public . account ( first_name , last_name ) values ( 'Foo' , 'Fooington' ); select jsonb_pretty ( graphql . resolve ( $$ { accountCollection { edges { node { id firstName lastName fullName } } } } $$ ) ); jsonb_pretty ------------------------------------------------------ { + \"data\" : { + \"accountCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : 1 , + \"fullName\" : \"Foo Fooington\" , + \"lastName\" : \"Fooington\" , + \"firstName\" : \"Foo\" + } + } + ] + } + } + } ( 1 row ) rollback ;","title":"PostgreSQL Builtin (Preferred)"},{"location":"computed_fields/#extending-types-with-functions","text":"For arbitrary computations that do not meet the requirements for generated columns , a table's reflected GraphQL type can be extended by creating a function that: accepts a single argument of the table's tuple type 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 begin ; comment on schema public is '@graphql({\"inflect_names\": true})' ; create table public . account ( id serial primary key , first_name varchar ( 255 ) not null , last_name varchar ( 255 ) not null , parent_id int references account ( id ) ); -- Extend with function create function public . _full_name ( rec public . account ) returns text immutable strict language sql as $$ select format ( '%s %s' , rec . first_name , rec . last_name ) $$ ; insert into public . account ( first_name , last_name , parent_id ) values ( 'Foo' , 'Fooington' , 1 ); select jsonb_pretty ( graphql . resolve ( $$ { accountCollection { edges { node { id firstName lastName fullName parent { fullName } } } } } $$ ) ); jsonb_pretty --------------------------------------------------------- { + \"data\" : { + \"accountCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : 1 , + \"parent\" : { + \"fullName\" : \"Foo Fooington\" + } , + \"fullName\" : \"Foo Fooington\" , + \"lastName\" : \"Fooington\" , + \"firstName\" : \"Foo\" + } + } + ] + } + } + } ( 1 row ) rollback ; If the function is written in SQL, its volatility can impact freshness of data returned in mutations: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 begin ; -- A computed field function written in SQL and marked stable might return stale results. -- Directly from the postgres docs(https://www.postgresql.org/docs/current/xfunc-volatility.html): --For functions written in SQL or in any of the standard procedural languages, --there is a second important property determined by the volatility category, --namely the visibility of any data changes that have been made by the SQL --command that is calling the function. A VOLATILE function will see such --changes, a STABLE or IMMUTABLE function will not. This behavior is --implemented using the snapshotting behavior of MVCC (see Chapter 13): STABLE --and IMMUTABLE functions use a snapshot established as of the start of the --calling query, whereas VOLATILE functions obtain a fresh snapshot at the --start of each query they execute. --The solution is to mark these functions as volatile create table parent ( id uuid primary key default gen_random_uuid (), count int2 ); create table child ( id uuid primary key default gen_random_uuid (), parent_id uuid references parent not null , count int2 ); -- note that the function is marked stable and in written in sql create or replace function _count ( rec parent ) returns smallint stable language sql as $$ select sum ( count ) from child where parent_id = rec . id $$ ; insert into parent ( id , count ) values ( '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 1 ); insert into child ( id , parent_id , count ) values ( '57738181-3d0f-45ad-96dd-3ba799b2d21d' , '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 2 ), ( 'cb5993ff-e693-49cd-9114-a6510707e628' , '8bcf0ee4-95ed-445f-808f-17b8194727ca' , 3 ); select jsonb_pretty ( graphql . resolve ( $$ query ParentQuery { parentCollection { edges { node { id count childCollection { edges { node { count } } } } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"parentCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 5 , + \"childCollection\" : { + \"edges\" : [ + { + \"node\" : { + \"count\" : 2 + } + } , + { + \"node\" : { + \"count\" : 3 + } + } + ] + } + } + } + ] + } + } + } ( 1 row ) -- since _count is stable, the value returned in parent.count field will be stale -- i.e. parent.count is still 5 instead of (3 + 5) = 8 select jsonb_pretty ( graphql . resolve ( $$ mutation ChildMutation { updateChildCollection ( filter : { id : { eq : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" } } set : { count : 5 } ) { records { id count parent { id count } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"updateChildCollection\" : { + \"records\" : [ + { + \"id\" : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" , + \"count\" : 5 , + \"parent\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 5 + } + } + ] + } + } + } ( 1 row ) -- note that the function is marked volatile create or replace function _count ( rec parent ) returns smallint volatile language sql as $$ select sum ( count ) from child where parent_id = rec . id $$ ; -- since _count is volatile, the value returned in parent.count field will be fresh -- i.e. parent.count is correctly at (3 + 7) 10 select jsonb_pretty ( graphql . resolve ( $$ mutation ChildMutation { updateChildCollection ( filter : { id : { eq : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" } } set : { count : 7 } ) { records { id count parent { id count } } } } $$ ) ); jsonb_pretty ----------------------------------------------------------------------- { + \"data\" : { + \"updateChildCollection\" : { + \"records\" : [ + { + \"id\" : \"57738181-3d0f-45ad-96dd-3ba799b2d21d\" , + \"count\" : 7 , + \"parent\" : { + \"id\" : \"8bcf0ee4-95ed-445f-808f-17b8194727ca\" , + \"count\" : 10 + } + } + ] + } + } + } ( 1 row ) rollback ;","title":"Extending Types with Functions"},{"location":"computed_fields/#computed-relationships","text":"Computed relations can be helpful to express relationships: between entities that don't support foreign keys too complex to be expressed via a foreign key If the relationship is simple, but involves an entity that does not support foreign keys e.g. Foreign Data Wrappers / Views, defining a comment directive is the easiest solution. See the view doc for a complete example. Note that for entities that do not support a primary key, like views, you must define one using a comment directive to use them in a computed relationship. Alternatively, if the relationship is complex, or you need compatibility with PostgREST, you can define a relationship using set returning functions.","title":"Computed Relationships"},{"location":"computed_fields/#to-one","text":"To One relationships can be defined using a function that returns setof <entity> rows 1 For example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 create table \"Person\" ( id int primary key , name text ); create table \"Address\" ( id int primary key , \"isPrimary\" bool not null default false , \"personId\" int references \"Person\" ( id ), address text ); -- Example computed relation create function \"primaryAddress\" ( \"Person\" ) returns setof \"Address\" rows 1 language sql as $$ select addr from \"Address\" addr where $ 1 . id = addr . \"personId\" and addr . \"isPrimary\" limit 1 $$ ; insert into \"Person\" ( id , name ) values ( 1 , 'Foo Barington' ); insert into \"Address\" ( id , \"isPrimary\" , \"personId\" , address ) values ( 4 , true , 1 , '1 Main St.' ); results in the GraphQL type Person 1 2 3 4 5 6 type Person implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! ... primaryAddress: Address } and can be queried like a natively enforced relationship Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { personCollection { edges { node { id name primaryAddress { address } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"Foo Barington\" , \"primaryAddress\" : { \"address\" : \"1 Main St.\" } } } ] } } }","title":"To-One"},{"location":"computed_fields/#to-many","text":"To-many relationships can be defined using a function that returns a setof <entity> For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 create table \"Person\" ( id int primary key , name text ); create table \"Address\" ( id int primary key , address text ); create table \"PersonAtAddress\" ( id int primary key , \"personId\" int not null , \"addressId\" int not null ); -- Computed relation to bypass \"PersonAtAddress\" table for cleaner API create function \"addresses\" ( \"Person\" ) returns setof \"Address\" language sql as $$ select addr from \"PersonAtAddress\" pa join \"Address\" addr on pa . \"addressId\" = \"addr\" . id where pa . \"personId\" = $ 1 . id $$ ; insert into \"Person\" ( id , name ) values ( 1 , 'Foo Barington' ); insert into \"Address\" ( id , address ) values ( 4 , '1 Main St.' ); insert into \"PersonAtAddress\" ( id , \"personId\" , \"addressId\" ) values ( 2 , 1 , 4 ); results in the GraphQL type Person 1 2 3 4 5 6 7 8 9 10 11 12 13 type Person implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! ... addresses ( first: Int last: Int before: Cursor after: Cursor filter: AddressFilter orderBy: [ AddressOrderBy !] ): AddressConnection } and can be queried like a natively enforced relationship Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 { personCollection { edges { node { id name addresses { edges { node { id address } } } } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"data\" : { \"personCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"name\" : \"Foo Barington\" , \"addresses\" : { \"edges\" : [ { \"node\" : { \"id\" : 4 , \"address\" : \"1 Main St.\" } } ] } } } ] } } }","title":"To-Many"},{"location":"configuration/","text":"Extra configuration options can be set on SQL entities using comment directives. Comment Directives Comment directives are snippets of configuration associated with SQL entities that alter how those entities behave. The format of a comment directive is 1 @ graphql ( < JSON > ) Inflection Inflection describes how SQL entities' names are transformed into GraphQL type and field names. By default, inflection is disabled and SQL names are literally interpolated such that 1 2 3 4 create table \"BlogPost\" ( id int primary key , ... ); results in GraphQL type names like 1 2 3 4 BlogPost BlogPostEdge BlogPostConnection ... Since snake case is a common casing structure for SQL types, pg_graphql support basic inflection from snake_case to PascalCase for type names, and snake_case to camelCase for field names to match Javascript conventions. The inflection directive can be applied at the schema level with: 1 comment on schema < schema_name > is e '@graphql({\"inflect_names\": true})' ; for example 1 2 3 4 5 6 comment on schema public is e '@graphql({\"inflect_names\": true})' ; create table blog_post ( id int primary key , ... ); similarly would generated the GraphQL type names 1 2 3 4 BlogPost BlogPostEdge BlogPostConnection ... For more fine grained adjustments to reflected names, see renaming . Max Rows The default page size for collections is 30 entries. To adjust the number of entries on each page, set a max_rows directive on the relevant schema entity. For example, to increase the max rows per page for each table in the public schema: 1 comment on schema public is e '@graphql({\"max_rows\": 100})' ; totalCount totalCount is an opt-in field that extends a table's Connection type. It provides a count of the rows that match the query's filters, and ignores pagination arguments. 1 2 3 4 5 6 7 type BlogPostConnection { edges: [ BlogPostEdge !]! pageInfo: PageInfo ! \"\"\"The total number of records matching the `filter` criteria\"\"\" totalCount: Int ! # this field } to enable totalCount for a table, use the directive 1 comment on table \"BlogPost\" is e '@graphql({\"totalCount\": {\"enabled\": true}})' ; for example 1 2 3 4 5 create table \"BlogPost\" ( id serial primary key , email varchar ( 255 ) not null ); comment on table \"BlogPost\" is e '@graphql({\"totalCount\": {\"enabled\": true}})' ; Renaming Table's Type Use the \"name\" JSON key to override a table's type name. 1 2 3 4 5 6 create table account ( id serial primary key ); comment on table public . account is e '@graphql({\"name\": \"AccountHolder\"})' ; results in: 1 2 3 type AccountHolder { # previously: \"Account\" id: Int ! } Column's Field Name Use the \"name\" JSON key to override a column's field name. 1 2 3 4 5 6 7 create table public . \"Account\" ( id serial primary key , email text ); comment on column \"Account\" . email is e '@graphql({\"name\": \"emailAddress\"})' ; results in: 1 2 3 4 5 type Account { nodeId: ID ! id: Int ! emailAddress: String ! # previously \"email\" } Computed Field Use the \"name\" JSON key to override a computed field's name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 create table \"Account\" ( id serial primary key , \"firstName\" varchar ( 255 ) not null , \"lastName\" varchar ( 255 ) not null ); -- Extend with function create function public . \"_fullName\" ( rec public . \"Account\" ) returns text immutable strict language sql as $$ select format ( '%s %s' , rec . \"firstName\" , rec . \"lastName\" ) $$ ; comment on function public . _full_name is e '@graphql({\"name\": \"displayName\"})' ; results in: 1 2 3 4 5 6 7 type Account { nodeId: ID ! id: Int ! firstName: String ! lastName: String ! displayName: String # previously \"fullName\" } Relationship's Field Use the \"local_name\" and \"foreign_name\" JSON keys to override a a relationships inbound and outbound field names. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 create table \"Account\" ( id serial primary key ); create table \"Post\" ( id serial primary key , \"accountId\" integer not null references \"Account\" ( id ), title text not null , body text ); comment on constraint post_owner_id_fkey on \"Post\" is E '@graphql({\"foreign_name\": \"author\", \"local_name\": \"posts\"})' ; results in: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type Post { nodeId: ID ! id: Int ! accountId: Int ! title: String ! body: String ! author: Account # was \"account\" } type Account { id: Int ! posts ( # was \"postCollection\" after: Cursor , before: Cursor , filter: PostFilter , first: Int , last: Int , orderBy: [ PostOrderBy !] ): PostConnection } Description Tables, Columns, and Functions accept a description directive to populate user defined descriptions in the GraphQL schema. 1 2 3 4 5 6 7 8 9 create table \"Account\" ( id serial primary key ); comment on table public . account is e '@graphql({\"description\": \"A User Account\"})' ; comment on column public . account . id is e '@graphql({\"description\": \"The primary key identifier\"})' ; 1 2 3 4 5 6 \"\"\"A User Account\"\"\" type Account implements Node { \"\"\"The primary key identifier\"\"\" id: Int ! } Enum Variant If a variant of a Postgres enum does not conform to GraphQL naming conventions, introspection returns an error: For example: 1 create type \"Algorithm\" as enum ( 'aead-ietf' ); causes the error: 1 2 3 4 5 6 7 { \"errors\" : [ { \"message\" : \"Names must only contain [_a-zA-Z0-9] but \\\"aead-ietf\\\" does not.\" , } ] } To resolve this problem, rename the invalid SQL enum variant to a GraphQL compatible name: 1 alter type \"Algorithm\" rename value 'aead-ietf' to 'AEAD_IETF' ; or, add a comment directive to remap the enum variant in the GraphQL API 1 comment on type \"Algorithm\" is '@graphql({\"mappings\": {\"aead-ietf\": \"AEAD_IETF\"}})' ; Which both result in the GraphQL enum: 1 2 3 enum Algorithm { AEAD_IETF }","title":"Configuration"},{"location":"configuration/#comment-directives","text":"Comment directives are snippets of configuration associated with SQL entities that alter how those entities behave. The format of a comment directive is 1 @ graphql ( < JSON > )","title":"Comment Directives"},{"location":"configuration/#inflection","text":"Inflection describes how SQL entities' names are transformed into GraphQL type and field names. By default, inflection is disabled and SQL names are literally interpolated such that 1 2 3 4 create table \"BlogPost\" ( id int primary key , ... ); results in GraphQL type names like 1 2 3 4 BlogPost BlogPostEdge BlogPostConnection ... Since snake case is a common casing structure for SQL types, pg_graphql support basic inflection from snake_case to PascalCase for type names, and snake_case to camelCase for field names to match Javascript conventions. The inflection directive can be applied at the schema level with: 1 comment on schema < schema_name > is e '@graphql({\"inflect_names\": true})' ; for example 1 2 3 4 5 6 comment on schema public is e '@graphql({\"inflect_names\": true})' ; create table blog_post ( id int primary key , ... ); similarly would generated the GraphQL type names 1 2 3 4 BlogPost BlogPostEdge BlogPostConnection ... For more fine grained adjustments to reflected names, see renaming .","title":"Inflection"},{"location":"configuration/#max-rows","text":"The default page size for collections is 30 entries. To adjust the number of entries on each page, set a max_rows directive on the relevant schema entity. For example, to increase the max rows per page for each table in the public schema: 1 comment on schema public is e '@graphql({\"max_rows\": 100})' ;","title":"Max Rows"},{"location":"configuration/#totalcount","text":"totalCount is an opt-in field that extends a table's Connection type. It provides a count of the rows that match the query's filters, and ignores pagination arguments. 1 2 3 4 5 6 7 type BlogPostConnection { edges: [ BlogPostEdge !]! pageInfo: PageInfo ! \"\"\"The total number of records matching the `filter` criteria\"\"\" totalCount: Int ! # this field } to enable totalCount for a table, use the directive 1 comment on table \"BlogPost\" is e '@graphql({\"totalCount\": {\"enabled\": true}})' ; for example 1 2 3 4 5 create table \"BlogPost\" ( id serial primary key , email varchar ( 255 ) not null ); comment on table \"BlogPost\" is e '@graphql({\"totalCount\": {\"enabled\": true}})' ;","title":"totalCount"},{"location":"configuration/#renaming","text":"","title":"Renaming"},{"location":"configuration/#tables-type","text":"Use the \"name\" JSON key to override a table's type name. 1 2 3 4 5 6 create table account ( id serial primary key ); comment on table public . account is e '@graphql({\"name\": \"AccountHolder\"})' ; results in: 1 2 3 type AccountHolder { # previously: \"Account\" id: Int ! }","title":"Table's Type"},{"location":"configuration/#columns-field-name","text":"Use the \"name\" JSON key to override a column's field name. 1 2 3 4 5 6 7 create table public . \"Account\" ( id serial primary key , email text ); comment on column \"Account\" . email is e '@graphql({\"name\": \"emailAddress\"})' ; results in: 1 2 3 4 5 type Account { nodeId: ID ! id: Int ! emailAddress: String ! # previously \"email\" }","title":"Column's Field Name"},{"location":"configuration/#computed-field","text":"Use the \"name\" JSON key to override a computed field's name. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 create table \"Account\" ( id serial primary key , \"firstName\" varchar ( 255 ) not null , \"lastName\" varchar ( 255 ) not null ); -- Extend with function create function public . \"_fullName\" ( rec public . \"Account\" ) returns text immutable strict language sql as $$ select format ( '%s %s' , rec . \"firstName\" , rec . \"lastName\" ) $$ ; comment on function public . _full_name is e '@graphql({\"name\": \"displayName\"})' ; results in: 1 2 3 4 5 6 7 type Account { nodeId: ID ! id: Int ! firstName: String ! lastName: String ! displayName: String # previously \"fullName\" }","title":"Computed Field"},{"location":"configuration/#relationships-field","text":"Use the \"local_name\" and \"foreign_name\" JSON keys to override a a relationships inbound and outbound field names. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 create table \"Account\" ( id serial primary key ); create table \"Post\" ( id serial primary key , \"accountId\" integer not null references \"Account\" ( id ), title text not null , body text ); comment on constraint post_owner_id_fkey on \"Post\" is E '@graphql({\"foreign_name\": \"author\", \"local_name\": \"posts\"})' ; results in: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type Post { nodeId: ID ! id: Int ! accountId: Int ! title: String ! body: String ! author: Account # was \"account\" } type Account { id: Int ! posts ( # was \"postCollection\" after: Cursor , before: Cursor , filter: PostFilter , first: Int , last: Int , orderBy: [ PostOrderBy !] ): PostConnection }","title":"Relationship's Field"},{"location":"configuration/#description","text":"Tables, Columns, and Functions accept a description directive to populate user defined descriptions in the GraphQL schema. 1 2 3 4 5 6 7 8 9 create table \"Account\" ( id serial primary key ); comment on table public . account is e '@graphql({\"description\": \"A User Account\"})' ; comment on column public . account . id is e '@graphql({\"description\": \"The primary key identifier\"})' ; 1 2 3 4 5 6 \"\"\"A User Account\"\"\" type Account implements Node { \"\"\"The primary key identifier\"\"\" id: Int ! }","title":"Description"},{"location":"configuration/#enum-variant","text":"If a variant of a Postgres enum does not conform to GraphQL naming conventions, introspection returns an error: For example: 1 create type \"Algorithm\" as enum ( 'aead-ietf' ); causes the error: 1 2 3 4 5 6 7 { \"errors\" : [ { \"message\" : \"Names must only contain [_a-zA-Z0-9] but \\\"aead-ietf\\\" does not.\" , } ] } To resolve this problem, rename the invalid SQL enum variant to a GraphQL compatible name: 1 alter type \"Algorithm\" rename value 'aead-ietf' to 'AEAD_IETF' ; or, add a comment directive to remap the enum variant in the GraphQL API 1 comment on type \"Algorithm\" is '@graphql({\"mappings\": {\"aead-ietf\": \"AEAD_IETF\"}})' ; Which both result in the GraphQL enum: 1 2 3 enum Algorithm { AEAD_IETF }","title":"Enum Variant"},{"location":"contributing/","text":"pg_graphql is OSS. PR and issues are welcome. Development Requirements: rust cargo pgrx Testing Tests are located in ./test/sql with expected output in ./test/expected To run tests locally, execute: 1 $ cargo pgrx install ; ./bin/installcheck Interactive PSQL Development To reduce the iteration cycle, you may want to launch a psql prompt with pg_graphql installed to experiment 1 cargo pgrx run pg14 Try out the commands below to spin up a database with the extension installed & query a table using GraphQL. Experiment with aliasing field/table names and filtering on different columns. 1 2 3 4 5 6 7 8 graphqldb = create extension pg_graphql cascade ; CREATE EXTENSION graphqldb = create table book ( id int primary key , title text ); CREATE TABLE graphqldb = insert into book ( id , title ) values ( 1 , 'book 1' ); INSERT 0 1 Finally, execute some graphql queries against the table. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 graphqldb = select graphql . resolve ( $$ query { bookCollection { edges { node { id } } } } $$ ); resolve ---------------------------------------------------------------------- { \"data\" : { \"bookCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }} ] }} , \"errors\" : [] } Documentation All public API must be documented. Building documentation requires python 3.6+ Install Dependencies Install mkdocs, themes, and extensions. 1 pip install -r docs/requirements_docs.txt Serving To serve the documentation locally run 1 mkdocs serve and visit the docs at http://127.0.0.1:8000/pg_graphql/","title":"Contributing"},{"location":"contributing/#development","text":"Requirements: rust cargo pgrx","title":"Development"},{"location":"contributing/#testing","text":"Tests are located in ./test/sql with expected output in ./test/expected To run tests locally, execute: 1 $ cargo pgrx install ; ./bin/installcheck","title":"Testing"},{"location":"contributing/#interactive-psql-development","text":"To reduce the iteration cycle, you may want to launch a psql prompt with pg_graphql installed to experiment 1 cargo pgrx run pg14 Try out the commands below to spin up a database with the extension installed & query a table using GraphQL. Experiment with aliasing field/table names and filtering on different columns. 1 2 3 4 5 6 7 8 graphqldb = create extension pg_graphql cascade ; CREATE EXTENSION graphqldb = create table book ( id int primary key , title text ); CREATE TABLE graphqldb = insert into book ( id , title ) values ( 1 , 'book 1' ); INSERT 0 1 Finally, execute some graphql queries against the table. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 graphqldb = select graphql . resolve ( $$ query { bookCollection { edges { node { id } } } } $$ ); resolve ---------------------------------------------------------------------- { \"data\" : { \"bookCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }} ] }} , \"errors\" : [] }","title":"Interactive PSQL Development"},{"location":"contributing/#documentation","text":"All public API must be documented. Building documentation requires python 3.6+","title":"Documentation"},{"location":"contributing/#install-dependencies","text":"Install mkdocs, themes, and extensions. 1 pip install -r docs/requirements_docs.txt","title":"Install Dependencies"},{"location":"contributing/#serving","text":"To serve the documentation locally run 1 mkdocs serve and visit the docs at http://127.0.0.1:8000/pg_graphql/","title":"Serving"},{"location":"example_schema/","text":"The following is a complete example showing how a sample SQL schema translates into a GraphQL schema. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 -- Turn on automatic inflection of type names comment on schema public is '@graphql({\"inflect_names\": true})' ; create table account ( id serial primary key , email varchar ( 255 ) not null , created_at timestamp not null , updated_at timestamp not null ); -- enable a `totalCount` field on the `account` query type comment on table account is e '@graphql({\"totalCount\": {\"enabled\": true}})' ; create table blog ( id serial primary key , owner_id integer not null references account ( id ), name varchar ( 255 ) not null , description varchar ( 255 ), created_at timestamp not null , updated_at timestamp not null ); create type blog_post_status as enum ( 'PENDING' , 'RELEASED' ); create table blog_post ( id uuid not null default uuid_generate_v4 () primary key , blog_id integer not null references blog ( id ), title varchar ( 255 ) not null , body varchar ( 10000 ), status blog_post_status not null , created_at timestamp not null , updated_at timestamp not null ); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 type Account implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! id: Int ! email: String ! createdAt: Datetime ! blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ): BlogConnection } type AccountConnection { edges: [ AccountEdge !]! pageInfo: PageInfo ! } type AccountDeleteResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Account !]! } type AccountEdge { cursor: String ! node: Account ! } input AccountFilter { nodeId: IDFilter id: IntFilter email: StringFilter createdAt: DatetimeFilter and: [ AccountFilter !] or: [ AccountFilter !] not: AccountFilter } input AccountInsertInput { email: String createdAt: Datetime } type AccountInsertResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Account !]! } input AccountOrderBy { id: OrderByDirection email: OrderByDirection createdAt: OrderByDirection } input AccountUpdateInput { email: String createdAt: Datetime } type AccountUpdateResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Account !]! } type Blog implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! id: Int ! ownerId: Int ! name: String ! description: String createdAt: Datetime ! owner: Account blogPostCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogPostFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogPostOrderBy !] ): BlogPostConnection } type BlogConnection { edges: [ BlogEdge !]! pageInfo: PageInfo ! } type BlogDeleteResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } type BlogEdge { cursor: String ! node: Blog ! } input BlogFilter { nodeId: IDFilter id: IntFilter ownerId: IntFilter name: StringFilter description: StringFilter createdAt: DatetimeFilter and: [ BlogFilter !] or: [ BlogFilter !] not: BlogFilter } input BlogInsertInput { ownerId: Int name: String description: String createdAt: Datetime } type BlogInsertResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } input BlogOrderBy { id: OrderByDirection ownerId: OrderByDirection name: OrderByDirection description: OrderByDirection createdAt: OrderByDirection } type BlogPost implements Node { \"\"\"Globally Unique Record Identifier\"\"\" nodeId: ID ! id: UUID ! blogId: Int ! title: String ! body: String status: BlogPostStatus ! createdAt: Datetime ! blog: Blog } type BlogPostConnection { edges: [ BlogPostEdge !]! pageInfo: PageInfo ! } type BlogPostDeleteResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ BlogPost !]! } type BlogPostEdge { cursor: String ! node: BlogPost ! } input BlogPostFilter { nodeId: IDFilter id: UUIDFilter blogId: IntFilter title: StringFilter body: StringFilter status: BlogPostStatusFilter createdAt: DatetimeFilter and: [ BlogPostFilter !] or: [ BlogPostFilter !] not: BlogPostFilter } input BlogPostInsertInput { id: UUID blogId: Int title: String body: String status: BlogPostStatus createdAt: Datetime } type BlogPostInsertResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ BlogPost !]! } input BlogPostOrderBy { id: OrderByDirection blogId: OrderByDirection title: OrderByDirection body: OrderByDirection status: OrderByDirection createdAt: OrderByDirection } enum FilterIs { PENDING RELEASED } enum BlogPostStatus { PENDING RELEASED } \"\"\" Boolean expression comparing fields on type \"BlogPostStatus\" \"\"\" input BlogPostStatusFilter { eq: BlogPostStatus in: [ BlogPostStatus !] neq: BlogPostStatus is: FilterIs } input BlogPostUpdateInput { id: UUID blogId: Int title: String body: String status: BlogPostStatus createdAt: Datetime } type BlogPostUpdateResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ BlogPost !]! } input BlogUpdateInput { ownerId: Int name: String description: String createdAt: Datetime } type BlogUpdateResponse { \"\"\"Count of the records impacted by the mutation\"\"\" affectedCount: Int ! \"\"\"Array of records impacted by the mutation\"\"\" records: [ Blog !]! } \"\"\" Boolean expression comparing fields on type \"ID\" \"\"\" input IDFilter { eq: ID } scalar BigInt \"\"\" Boolean expression comparing fields on type \"BigInt\" \"\"\" input BigIntFilter { eq: BigInt gt: BigInt gte: BigInt in: [ BigInt !] lt: BigInt lte: BigInt neq: BigInt is: FilterIs } scalar BigFloat \"\"\" Boolean expression comparing fields on type \"BigInt\" \"\"\" input BigFloatFilter { eq: BigFloat gt: BigFloat gte: BigFloat in: [ BigFloat !] lt: BigFloat lte: BigFloat neq: BigFloat is: FilterIs } \"\"\" Boolean expression comparing fields on type \"Boolean\" \"\"\" input BooleanFilter { eq: Boolean is: FilterIs } scalar Opaque \"\"\" Boolean expression comparing fields on type \"Opaque\" \"\"\" input OpaqueFilter { eq: Opaque is: FilterIs } scalar Cursor scalar Date \"\"\" Boolean expression comparing fields on type \"Date\" \"\"\" input DateFilter { eq: Date gt: Date gte: Date in: [ Date !] lt: Date lte: Date neq: Date is: FilterIs } scalar Datetime \"\"\" Boolean expression comparing fields on type \"Datetime\" \"\"\" input DatetimeFilter { eq: Datetime gt: Datetime gte: Datetime in: [ Datetime !] lt: Datetime lte: Datetime neq: Datetime is: FilterIs } \"\"\" Boolean expression comparing fields on type \"Float\" \"\"\" input FloatFilter { eq: Float gt: Float gte: Float in: [ Float !] lt: Float lte: Float neq: Float is: FilterIs } \"\"\" Boolean expression comparing fields on type \"Int\" \"\"\" input IntFilter { eq: Int gt: Int gte: Int in: [ Int !] lt: Int lte: Int neq: Int is: FilterIs } scalar JSON \"\"\"The root type for creating and mutating data\"\"\" type Mutation { \"\"\"Deletes zero or more records from the `Account` collection\"\"\" deleteFromAccountCollection ( \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: AccountFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): AccountDeleteResponse ! \"\"\"Deletes zero or more records from the `Blog` collection\"\"\" deleteFromBlogCollection ( \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogDeleteResponse ! \"\"\"Deletes zero or more records from the `BlogPost` collection\"\"\" deleteFromBlogPostCollection ( \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: BlogPostFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogPostDeleteResponse ! \"\"\"Adds one or more `Account` records to the collection\"\"\" insertIntoAccountCollection ( objects: [ AccountInsertInput !]!): AccountInsertResponse \"\"\"Adds one or more `Blog` records to the collection\"\"\" insertIntoBlogCollection ( objects: [ BlogInsertInput !]!): BlogInsertResponse \"\"\"Adds one or more `BlogPost` records to the collection\"\"\" insertIntoBlogPostCollection ( objects: [ BlogPostInsertInput !]!): BlogPostInsertResponse \"\"\"Updates zero or more records in the `Account` collection\"\"\" updateAccountCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: AccountUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: AccountFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): AccountUpdateResponse ! \"\"\"Updates zero or more records in the `Blog` collection\"\"\" updateBlogCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: BlogFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogUpdateResponse ! \"\"\"Updates zero or more records in the `BlogPost` collection\"\"\" updateBlogPostCollection ( \"\"\" Fields that are set will be updated for all records matching the `filter` \"\"\" set: BlogPostUpdateInput ! \"\"\"Restricts the mutation's impact to records matching the criteria\"\"\" filter: BlogPostFilter \"\"\" The maximum number of records in the collection permitted to be affected \"\"\" atMost: Int ! = 1 ): BlogPostUpdateResponse ! } interface Node { \"\"\"Retrieves a record by `ID`\"\"\" nodeId: ID ! } \"\"\"Defines a per-field sorting order\"\"\" enum OrderByDirection { \"\"\"Ascending order, nulls first\"\"\" AscNullsFirst \"\"\"Ascending order, nulls last\"\"\" AscNullsLast \"\"\"Descending order, nulls first\"\"\" DescNullsFirst \"\"\"Descending order, nulls last\"\"\" DescNullsLast } type PageInfo { endCursor: String hasNextPage: Boolean ! hasPreviousPage: Boolean ! startCursor: String } \"\"\"The root type for querying data\"\"\" type Query { \"\"\"A pagable collection of type `Account`\"\"\" accountCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: AccountFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ AccountOrderBy !] ): AccountConnection \"\"\"A pagable collection of type `Blog`\"\"\" blogCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogOrderBy !] ): BlogConnection \"\"\"A pagable collection of type `BlogPost`\"\"\" blogPostCollection ( \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: BlogPostFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ BlogPostOrderBy !] ): BlogPostConnection \"\"\"Retrieve a record by its `ID`\"\"\" node ( \"\"\"The record's `ID`\"\"\" nodeId: ID ! ): Node } \"\"\" Boolean expression comparing fields on type \"String\" \"\"\" input StringFilter { eq: String gt: String gte: String in: [ String !] lt: String lte: String neq: String is: FilterIs startsWith: String like: String ilike: String regex: String iregex: String } scalar Time \"\"\" Boolean expression comparing fields on type \"Time\" \"\"\" input TimeFilter { eq: Time gt: Time gte: Time in: [ Time !] lt: Time lte: Time neq: Time is: FilterIs } scalar UUID \"\"\" Boolean expression comparing fields on type \"UUID\" \"\"\" input UUIDFilter { eq: UUID in: [ UUID !] neq: UUID is: FilterIs }","title":"Example Schema"},{"location":"functions/","text":"Functions can be exposed by pg_graphql to allow running custom queries or mutations. Query vs Mutation For example, a function to add two numbers will be available on the query type as a field: Function QueryType Query Response 1 2 3 4 5 create function \"addNums\" ( a int , b int ) returns int immutable language sql as $$ select a + b ; $$ ; 1 2 3 type Query { addNums ( a : Int ! , b : Int !): Int } 1 2 3 query { addNums ( a : 2 , b : 3 ) } 1 2 3 4 5 { \"data\" : { \"addNums\" : 5 } } Functions marked immutable or stable are available on the query type. Functions marked with the default volatile category are available on the mutation type: Function MutationType Query Response 1 2 3 4 5 6 7 8 9 10 create table account ( id serial primary key , email varchar ( 255 ) not null ); create function \"addAccount\" ( email text ) returns int volatile language sql as $$ insert into account ( email ) values ( email ) returning id ; $$ ; 1 2 3 type Mutation { addAccount ( email: String !): Int } 1 2 3 mutation { addAccount ( email: \"email@example.com\" ) } 1 2 3 4 5 { \"data\" : { \"addAccount\" : 1 } } Supported Return Types Built-in GraphQL scalar types Int , Float , String , Boolean and custom scalar types are supported as function arguments and return types. Function types returning a table or view are supported as well. Such functions implement the Node interface : Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table account ( id serial primary key , email varchar ( 255 ) not null ); insert into account ( email ) values ( 'a@example.com' ), ( 'b@example.com' ); create function \"accountById\" ( \"accountId\" int ) returns account stable language sql as $$ select id , email from account where id = \"accountId\" ; $$ ; 1 2 3 type Query { accountById ( email: String !): Account } 1 2 3 4 5 6 7 query { accountById ( accountId: 1 ) { id email nodeId } } 1 2 3 4 5 6 7 8 9 { \"data\" : { \"accountById\" : { \"id\" : 1 , \"email\" : \"a@example.com\" \"nodeId\" : \"WyJwdWJsaWMiLCAiYWNjb3VudCIsIDFd\" } } } Since Postgres considers a row/composite type containing only null values to be null, the result can be a little surprising in this case. Instead of an object with all columns null, the top-level field is null: Function Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table account ( id int , email varchar ( 255 ), name text null ); insert into account ( id , email , name ) values ( 1 , 'aardvark@x.com' , 'aardvark' ), ( 2 , 'bat@x.com' , null ), ( null , null , null ); create function \"returnsAccountWithAllNullColumns\" () returns account language sql stable as $$ select id , email , name from account where id is null ; $$ ; 1 2 3 4 5 6 7 8 query { returnsAccountWithAllNullColumns { id email name __typename } } 1 2 3 4 5 { \"data\" : { \"returnsAccountWithAllNullColumns\" : null } } Functions returning multiple rows of a table or view are exposed as collections . Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 create table \"Account\" ( id serial primary key , email varchar ( 255 ) not null ); insert into \"Account\" ( email ) values ( 'a@example.com' ), ( 'a@example.com' ), ( 'b@example.com' ); create function \"accountsByEmail\" ( \"emailToSearch\" text ) returns setof \"Account\" stable language sql as $$ select id , email from \"Account\" where email = \"emailToSearch\" ; $$ ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Query { accountsByEmail ( emailToSearch: String ! \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: AccountFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ AccountOrderBy !] ): AccountConnection } 1 2 3 4 5 6 7 8 9 10 query { accountsByEmail ( emailToSearch: \"a@example.com\" , first: 1 ) { edges { node { id email } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"accountsByEmail\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"email\" : \"a@example.com\" } } ] } } } Note A set returning function with any of its argument names clashing with argument names of a collection ( first , last , before , after , filter , or orderBy ) will not be exposed. Functions accepting or returning arrays of non-composite types are also supported. In the following example, the ids array is used to filter rows from the Account table: Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 create table \"Account\" ( id serial primary key , email varchar ( 255 ) not null ); insert into \"Account\" ( email ) values ( 'a@example.com' ), ( 'b@example.com' ), ( 'c@example.com' ); create function \"accountsByIds\" ( \"ids\" int []) returns setof \"Account\" stable language sql as $$ select id , email from \"Account\" where id = any ( ids ); $$ ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Query { accountsByIds ( ids: Int []! \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: AccountFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ AccountOrderBy !] ): AccountConnection } 1 2 3 4 5 6 7 8 9 10 query { accountsByIds ( ids: [ 1 , 2 ]) { edges { node { id email } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"data\" : { \"accountsByIds\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"email\" : \"a@example.com\" } }, { \"node\" : { \"id\" : 2 , \"email\" : \"b@example.com\" } } ] } } } Default Arguments Functions with default arguments can have their default arguments omitted. Function QueryType Query Response 1 2 3 4 5 create function \"addNums\" ( a int default 1 , b int default 2 ) returns int immutable language sql as $$ select a + b ; $$ ; 1 2 3 type Query { addNums ( a : Int , b : Int ): Int } 1 2 3 query { addNums ( b : 20 ) } 1 2 3 4 5 { \"data\" : { \"addNums\" : 21 } } Limitations The following features are not yet supported. Any function using these features is not exposed in the API: Functions that accept a table's tuple type Overloaded functions Functions with a nameless argument Functions returning void Variadic functions Functions that accept or return an array of composite type Functions that accept or return an enum type or an array of enum type","title":"Functions"},{"location":"functions/#query-vs-mutation","text":"For example, a function to add two numbers will be available on the query type as a field: Function QueryType Query Response 1 2 3 4 5 create function \"addNums\" ( a int , b int ) returns int immutable language sql as $$ select a + b ; $$ ; 1 2 3 type Query { addNums ( a : Int ! , b : Int !): Int } 1 2 3 query { addNums ( a : 2 , b : 3 ) } 1 2 3 4 5 { \"data\" : { \"addNums\" : 5 } } Functions marked immutable or stable are available on the query type. Functions marked with the default volatile category are available on the mutation type: Function MutationType Query Response 1 2 3 4 5 6 7 8 9 10 create table account ( id serial primary key , email varchar ( 255 ) not null ); create function \"addAccount\" ( email text ) returns int volatile language sql as $$ insert into account ( email ) values ( email ) returning id ; $$ ; 1 2 3 type Mutation { addAccount ( email: String !): Int } 1 2 3 mutation { addAccount ( email: \"email@example.com\" ) } 1 2 3 4 5 { \"data\" : { \"addAccount\" : 1 } }","title":"Query vs Mutation"},{"location":"functions/#supported-return-types","text":"Built-in GraphQL scalar types Int , Float , String , Boolean and custom scalar types are supported as function arguments and return types. Function types returning a table or view are supported as well. Such functions implement the Node interface : Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table account ( id serial primary key , email varchar ( 255 ) not null ); insert into account ( email ) values ( 'a@example.com' ), ( 'b@example.com' ); create function \"accountById\" ( \"accountId\" int ) returns account stable language sql as $$ select id , email from account where id = \"accountId\" ; $$ ; 1 2 3 type Query { accountById ( email: String !): Account } 1 2 3 4 5 6 7 query { accountById ( accountId: 1 ) { id email nodeId } } 1 2 3 4 5 6 7 8 9 { \"data\" : { \"accountById\" : { \"id\" : 1 , \"email\" : \"a@example.com\" \"nodeId\" : \"WyJwdWJsaWMiLCAiYWNjb3VudCIsIDFd\" } } } Since Postgres considers a row/composite type containing only null values to be null, the result can be a little surprising in this case. Instead of an object with all columns null, the top-level field is null: Function Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table account ( id int , email varchar ( 255 ), name text null ); insert into account ( id , email , name ) values ( 1 , 'aardvark@x.com' , 'aardvark' ), ( 2 , 'bat@x.com' , null ), ( null , null , null ); create function \"returnsAccountWithAllNullColumns\" () returns account language sql stable as $$ select id , email , name from account where id is null ; $$ ; 1 2 3 4 5 6 7 8 query { returnsAccountWithAllNullColumns { id email name __typename } } 1 2 3 4 5 { \"data\" : { \"returnsAccountWithAllNullColumns\" : null } } Functions returning multiple rows of a table or view are exposed as collections . Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 create table \"Account\" ( id serial primary key , email varchar ( 255 ) not null ); insert into \"Account\" ( email ) values ( 'a@example.com' ), ( 'a@example.com' ), ( 'b@example.com' ); create function \"accountsByEmail\" ( \"emailToSearch\" text ) returns setof \"Account\" stable language sql as $$ select id , email from \"Account\" where email = \"emailToSearch\" ; $$ ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Query { accountsByEmail ( emailToSearch: String ! \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: AccountFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ AccountOrderBy !] ): AccountConnection } 1 2 3 4 5 6 7 8 9 10 query { accountsByEmail ( emailToSearch: \"a@example.com\" , first: 1 ) { edges { node { id email } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"data\" : { \"accountsByEmail\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"email\" : \"a@example.com\" } } ] } } } Note A set returning function with any of its argument names clashing with argument names of a collection ( first , last , before , after , filter , or orderBy ) will not be exposed. Functions accepting or returning arrays of non-composite types are also supported. In the following example, the ids array is used to filter rows from the Account table: Function QueryType Query Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 create table \"Account\" ( id serial primary key , email varchar ( 255 ) not null ); insert into \"Account\" ( email ) values ( 'a@example.com' ), ( 'b@example.com' ), ( 'c@example.com' ); create function \"accountsByIds\" ( \"ids\" int []) returns setof \"Account\" stable language sql as $$ select id , email from \"Account\" where id = any ( ids ); $$ ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Query { accountsByIds ( ids: Int []! \"\"\"Query the first `n` records in the collection\"\"\" first: Int \"\"\"Query the last `n` records in the collection\"\"\" last: Int \"\"\"Query values in the collection before the provided cursor\"\"\" before: Cursor \"\"\"Query values in the collection after the provided cursor\"\"\" after: Cursor \"\"\"Filters to apply to the results set when querying from the collection\"\"\" filter: AccountFilter \"\"\"Sort order to apply to the collection\"\"\" orderBy: [ AccountOrderBy !] ): AccountConnection } 1 2 3 4 5 6 7 8 9 10 query { accountsByIds ( ids: [ 1 , 2 ]) { edges { node { id email } } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { \"data\" : { \"accountsByIds\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 , \"email\" : \"a@example.com\" } }, { \"node\" : { \"id\" : 2 , \"email\" : \"b@example.com\" } } ] } } }","title":"Supported Return Types"},{"location":"functions/#default-arguments","text":"Functions with default arguments can have their default arguments omitted. Function QueryType Query Response 1 2 3 4 5 create function \"addNums\" ( a int default 1 , b int default 2 ) returns int immutable language sql as $$ select a + b ; $$ ; 1 2 3 type Query { addNums ( a : Int , b : Int ): Int } 1 2 3 query { addNums ( b : 20 ) } 1 2 3 4 5 { \"data\" : { \"addNums\" : 21 } }","title":"Default Arguments"},{"location":"functions/#limitations","text":"The following features are not yet supported. Any function using these features is not exposed in the API: Functions that accept a table's tuple type Overloaded functions Functions with a nameless argument Functions returning void Variadic functions Functions that accept or return an array of composite type Functions that accept or return an enum type or an array of enum type","title":"Limitations"},{"location":"installation/","text":"First, install pgrx by running cargo install --locked cargo-pgrx@version , where version should be compatible with the pgrx version used by pg_graphl Then clone the repo and install using 1 2 3 git clone https://github.com/supabase/pg_graphql.git cd pg_graphql cargo pgrx install --release To enable the extension in PostgreSQL we must execute a create extension statement. The extension creates its own schema/namespace named graphql to avoid naming conflicts. 1 create extension pg_graphql ;","title":"Installation"},{"location":"quickstart/","text":"If you are new to the project, start here. The easiest way to try pg_graphql is to run the interactive GraphiQL IDE demo. The demo environment launches a database, webserver and the GraphiQL IDE/API explorer with a small pre-populated schema. Requires: git docker-compose First, clone the repo 1 2 git clone https://github.com/supabase/pg_graphql.git cd pg_graphql Next, launch the demo with docker-compose. 1 docker-compose up Finally, access GraphiQL at http://localhost:4000/ .","title":"Quickstart"},{"location":"security/","text":"pg_graphql fully respects builtin PostgreSQL role and row security. Table/Column Visibility Table and column visibility in the GraphQL schema are controlled by standard PostgreSQL role permissions. Revoking SELECT access from the user/role executing queries removes that entity from the visible schema. For example: 1 revoke all privileges on public . \"Account\" from api_user ; removes the Account GraphQL type. Similarly, revoking SELECT access on a table's column will remove that field from the associated GraphQL type/s. The permissions SELECT , INSERT , UPDATE , and DELETE all impact the relevant sections of the GraphQL schema. Row Visibility Visibility of rows in a given table can be configured using PostgreSQL's built-in row level security policies.","title":"Security"},{"location":"security/#tablecolumn-visibility","text":"Table and column visibility in the GraphQL schema are controlled by standard PostgreSQL role permissions. Revoking SELECT access from the user/role executing queries removes that entity from the visible schema. For example: 1 revoke all privileges on public . \"Account\" from api_user ; removes the Account GraphQL type. Similarly, revoking SELECT access on a table's column will remove that field from the associated GraphQL type/s. The permissions SELECT , INSERT , UPDATE , and DELETE all impact the relevant sections of the GraphQL schema.","title":"Table/Column Visibility"},{"location":"security/#row-visibility","text":"Visibility of rows in a given table can be configured using PostgreSQL's built-in row level security policies.","title":"Row Visibility"},{"location":"sql_interface/","text":"pg_graphql's public facing SQL interface consists of a single SQL function to resolve GraphQL requests. All other entities in the graphql schema are private. graphql.resolve description Resolves a GraphQL query, returning JSONB. signature 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 graphql . resolve ( -- graphql query/mutation query text , -- json key/values pairs for variables variables jsonb default '{}' :: jsonb , -- the name of the graphql operation in *query* to execute \"operationName\" text default null , -- extensions to include in the request extensions jsonb default null , ) returns jsonb strict volatile parallel safe language plpgsql usage 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- Create the extension graphqldb = create extension pg_graphql ; CREATE EXTENSION -- Create an example table graphqldb = create table book ( id int primary key , title text ); CREATE TABLE -- Insert a record graphqldb = insert into book ( id , title ) values ( 1 , 'book 1' ); INSERT 0 1 -- Query the table via GraphQL graphqldb = select graphql . resolve ( $$ query { bookCollection { edges { node { id } } } } $$ ); resolve ---------------------------------------------------------------------- { \"data\" : { \"bookCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }} ] }} , \"errors\" : [] }","title":"SQL Interface"},{"location":"sql_interface/#graphqlresolve","text":"","title":"graphql.resolve"},{"location":"sql_interface/#description","text":"Resolves a GraphQL query, returning JSONB.","title":"description"},{"location":"sql_interface/#signature","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 graphql . resolve ( -- graphql query/mutation query text , -- json key/values pairs for variables variables jsonb default '{}' :: jsonb , -- the name of the graphql operation in *query* to execute \"operationName\" text default null , -- extensions to include in the request extensions jsonb default null , ) returns jsonb strict volatile parallel safe language plpgsql","title":"signature"},{"location":"sql_interface/#usage","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- Create the extension graphqldb = create extension pg_graphql ; CREATE EXTENSION -- Create an example table graphqldb = create table book ( id int primary key , title text ); CREATE TABLE -- Insert a record graphqldb = insert into book ( id , title ) values ( 1 , 'book 1' ); INSERT 0 1 -- Query the table via GraphQL graphqldb = select graphql . resolve ( $$ query { bookCollection { edges { node { id } } } } $$ ); resolve ---------------------------------------------------------------------- { \"data\" : { \"bookCollection\" : { \"edges\" : [ { \"node\" : { \"id\" : 1 }} ] }} , \"errors\" : [] }","title":"usage"},{"location":"supabase/","text":"The Supabase GraphQL API is automatically reflected from your database's schema using pg_graphql . It supports: Basic CRUD operations (Create/Read/Update/Delete) Support for Tables, Views, Materialized Views, and Foreign Tables Arbitrarily deep relationships among tables/views User defined computed fields Postgres' security model - including Row Level Security, Roles, and Grants All requests resolve in a single round-trip leading to fast response times and high throughput. If you haven't created a Supabase project, do that here so you can follow along with the guide. Quickstart https://<PROJECT_REF>.supabase.co/graphql/v1 is your project's GraphQL API endpoint. See PROJECT_REF for instructions on finding your project's reference. Note that the url does not allow a trailing / . To access the API you MUST provide your project's API key as a header in every request. For example see line 2 of the cURL request below. 1 2 3 4 curl -X POST https://<PROJECT_REF>.supabase.co/graphql/v1 \\ -H 'apiKey: <API_KEY>' \\ -H 'Content-Type: application/json' \\ --data-raw '{\"query\": \"{ accountCollection(first: 1) { edges { node { id } } } }\", \"variables\": {}}' For user authentication, pass an Authorization header e.g. 1 -H 'Authorization: Bearer <JWT>' See the auth docs to understand how to sign-up/sign-in users to your application and retrieve a JWT. The apollo and relay guides also include complete examples of using Supabase Auth with GraphQL. Supabase Auth works with row level security (RLS) allowing you to control which users can access tables/rows. The fastest way to get started with GraphQL on Supabase is using the GraphQL IDE (GraphiQL) built directly into Supabase Studio . Clients If you're new to GraphQL or Supabase, we strongly recommend starting with Supabase GraphQL by following the Supabase Studio guide . For more experienced users, or when you're ready to productionize your application, access the API using supabase-js , GraphiQL , or any HTTP client, for example cURL . Supabase Studio The easiest way to make a GraphQL request with Supabase is to use Supabase Studio's builtin GraphiQL IDE . You can access GraphiQL here by selecting the relevant project. Alternatively, navigate there within Studio at API Docs > GraphQL > GraphiQL . Type queries in the central query editor and use the green icon to submit requests to the server. Results are shown in the output display to the right of the editor. To explore the API visually, select the docs icon shown below and navigate through each type to see how they connect to the Graph. pg_graphql mirrors the structure of the project's SQL schema in the GraphQL API. If your project is new and empty, the GraphQL API will be empty as well, with the exception of basic introspection types. For a more interesting result, go to the SQL or table editor and create a table. Head back to GraphiQL to see the new table reflected in your GraphQL API's Query and Mutation types. If you'd like your type and field names to match the GraphQL convention of PascalCase for types and camelCase for fields, check out the pg_graphql inflection guide . HTTP Request To access the GraphQL API over HTTP, first collect your project reference and API Key . cURL To hit the Supabase GraphQL API using cURL, submit a POST request to your GraphQL API's URL shown below, substituting in your PROJECT_REF and passing the project's API_KEY as the apiKey header: 1 2 3 4 curl -X POST https://<PROJECT_REF>.supabase.co/graphql/v1 \\ -H 'apiKey: <API_KEY>' \\ -H 'Content-Type: application/json' \\ --data-raw '{\"query\": \"{ accountCollection(first: 1) { edges { node { id } } } }\", \"variables\": {}}' In that example, the GraphQL query is 1 2 3 4 5 6 7 8 9 { accountCollection ( first: 1 ) { edges { node { id } } } } and there are no variables 1 {} supabase-js The JS ecosystem supports multiple prominent GraphQL frameworks. supabase-js is unopinionated about your GraphQL tooling and can integrate with all of them. For an example integration, check out the Relay guide , complete with Supabase Auth support. GraphiQL If you'd prefer to connect to Supabase GraphQL using an external IDE like GraphiQL, save the HTML snippet below as supabase_graphiql.html and open it in your browser. Be sure to substitute in your PROJECT_REF and API_KEY beneath the EDIT BELOW comment: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 < html > < head > < title > GraphiQL </ title > < link href = \"https://cdnjs.cloudflare.com/ajax/libs/graphiql/2.4.7/graphiql.css\" rel = \"stylesheet\" /> </ head > < body style = \"margin: 0;\" > < div id = \"graphiql\" style = \"height: 100vh;\" ></ div > < script crossorigin src = \"https://unpkg.com/react@18/umd/react.production.min.js\" ></ script > < script crossorigin src = \"https://unpkg.com/react-dom@18/umd/react-dom.production.min.js\" ></ script > < script crossorigin src = \"https://cdnjs.cloudflare.com/ajax/libs/graphiql/2.4.7/graphiql.js\" ></ script > < script > //////////////// // EDIT BELOW // //////////////// const fetcher = GraphiQL . createFetcher ({ url : 'https://<PROJECT_REF>.supabase.co/graphql/v1' , headers : { \"apiKey\" : \"<API_KEY>\" , } }); ReactDOM . render ( React . createElement ( GraphiQL , { fetcher : fetcher }), document . getElementById ( 'graphiql' ), ); </ script > </ body > </ html > Schema & Table Visibility pg_graphql uses Postgres' search_path and permissions system to determine which schemas and entities are exposed in the GraphQL schema. By default on Supabase, tables, views, and functions in the public schema are visible to anonymous ( anon ) and logged in ( authenticated ) roles. Remove a Table from the API To remove a table from the GraphQL API, you can revoke permission on that table from the the relevant role. For example, to remove table foo from the API for anonymous users you could run: 1 revoke all on table public . foo from anon ; You can similarly revoke permissions using the more granular insert , update , delete , and truncate permissions to remove individual entrypoints in the GraphQL API. For example, revoking update permission removes the updateFooCollection entrypoing in the API's Mutation type. Add a Schema to the API Adding a schema to the GraphQL API is a two step process. First, we need to add the new schema to the API search path. In the example below, we add a comma separated value for the new app schema: Next, make sure the schema and entities (tables/views/functions) that you intend to expose are accessible by the relevant roles. For example, to match permissions from the public schema: 1 2 3 4 5 6 7 grant usage on schema app to anon , authenticated , service_role ; grant all privileges on all tables in schema app to anon , authenticated , service_role ; grant all privileges on all routines in schema app to anon , authenticated , service_role ; grant all privileges on all sequences in schema app to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on tables to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on routines to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on sequences to anon , authenticated , service_role ; Note that in practice you likely prefer a more secure set of permissions, particularly for anonymous API users. Version Management To maximize stability, you are in control of when to upgrade your GraphQL API. To see which version of pg_graphql you have, and the highest upgrade version available, execute: 1 select * from pg_available_extensions where name = 'pg_graphql' Which returns a table, for example: name default_version installed_version comment pg_graphql 1.2.0 1.1.0 GraphQL support The default_version is the highest version available on your database. The installed_version is the version currently enabled in your database. If the two differ, as in the example, you can upgrade your installed version by running: 1 2 drop extension pg_graphql ; -- drop version 1.1.0 create extension pg_graphql ; -- install default version 1.2.0 To upgrade your GraphQL API with 0 downtime. When making a decision to upgrade, you can review features of the upgraded version in the changelog . Always test a new version of pg_graphql extensively on a development or staging instance before updating your production instance. pg_graphql follows SemVer, which makes API backwards compatibility relatively safe for minor and patch updates. Even so, it's critical to verify that changes do not negatively impact the specifics of your project's API in other ways, e.g. requests/sec or CPU load. Local Development When starting a local project through the Supabase CLI , the output of supabase start provides the information needed to call the GraphQL API directly. You can also use the Supabase Studio url to access the builtin GraphiQL IDE . 1 2 3 4 5 6 7 8 9 10 11 12 > supabase start ... Started supabase local development setup. GraphQL URL: http://localhost:54321/graphql/v1 <-- GraphQL endpoint DB URL: ... Studio URL: http://localhost:54323 <-- Supabase Studio Inbucket URL: ... JWT secret: ... anon key: eyJhbGciOiJIUzI1...<truncated> <-- API_KEY service_role key: ... Term Reference Project Reference (PROJECT_REF) Your Supabase project reference or PROJECT_REF is a 20 digit unique identifier for your project, for example bvykdyhlwawojivopztl . The project reference is used throughout your supabase application including the project's API URL. You can find the project reference in by logging in to Supabase Studio and navigating to Settings > General > Project Settings > Reference ID API Key (API_KEY) Your Supabase API Key is a public value that must be sent with every API request. The key is visible in Supabase Studio at Settings > API > Project API keys","title":"Supabase"},{"location":"supabase/#quickstart","text":"https://<PROJECT_REF>.supabase.co/graphql/v1 is your project's GraphQL API endpoint. See PROJECT_REF for instructions on finding your project's reference. Note that the url does not allow a trailing / . To access the API you MUST provide your project's API key as a header in every request. For example see line 2 of the cURL request below. 1 2 3 4 curl -X POST https://<PROJECT_REF>.supabase.co/graphql/v1 \\ -H 'apiKey: <API_KEY>' \\ -H 'Content-Type: application/json' \\ --data-raw '{\"query\": \"{ accountCollection(first: 1) { edges { node { id } } } }\", \"variables\": {}}' For user authentication, pass an Authorization header e.g. 1 -H 'Authorization: Bearer <JWT>' See the auth docs to understand how to sign-up/sign-in users to your application and retrieve a JWT. The apollo and relay guides also include complete examples of using Supabase Auth with GraphQL. Supabase Auth works with row level security (RLS) allowing you to control which users can access tables/rows. The fastest way to get started with GraphQL on Supabase is using the GraphQL IDE (GraphiQL) built directly into Supabase Studio .","title":"Quickstart"},{"location":"supabase/#clients","text":"If you're new to GraphQL or Supabase, we strongly recommend starting with Supabase GraphQL by following the Supabase Studio guide . For more experienced users, or when you're ready to productionize your application, access the API using supabase-js , GraphiQL , or any HTTP client, for example cURL .","title":"Clients"},{"location":"supabase/#supabase-studio","text":"The easiest way to make a GraphQL request with Supabase is to use Supabase Studio's builtin GraphiQL IDE . You can access GraphiQL here by selecting the relevant project. Alternatively, navigate there within Studio at API Docs > GraphQL > GraphiQL . Type queries in the central query editor and use the green icon to submit requests to the server. Results are shown in the output display to the right of the editor. To explore the API visually, select the docs icon shown below and navigate through each type to see how they connect to the Graph. pg_graphql mirrors the structure of the project's SQL schema in the GraphQL API. If your project is new and empty, the GraphQL API will be empty as well, with the exception of basic introspection types. For a more interesting result, go to the SQL or table editor and create a table. Head back to GraphiQL to see the new table reflected in your GraphQL API's Query and Mutation types. If you'd like your type and field names to match the GraphQL convention of PascalCase for types and camelCase for fields, check out the pg_graphql inflection guide .","title":"Supabase Studio"},{"location":"supabase/#http-request","text":"To access the GraphQL API over HTTP, first collect your project reference and API Key .","title":"HTTP Request"},{"location":"supabase/#curl","text":"To hit the Supabase GraphQL API using cURL, submit a POST request to your GraphQL API's URL shown below, substituting in your PROJECT_REF and passing the project's API_KEY as the apiKey header: 1 2 3 4 curl -X POST https://<PROJECT_REF>.supabase.co/graphql/v1 \\ -H 'apiKey: <API_KEY>' \\ -H 'Content-Type: application/json' \\ --data-raw '{\"query\": \"{ accountCollection(first: 1) { edges { node { id } } } }\", \"variables\": {}}' In that example, the GraphQL query is 1 2 3 4 5 6 7 8 9 { accountCollection ( first: 1 ) { edges { node { id } } } } and there are no variables 1 {}","title":"cURL"},{"location":"supabase/#supabase-js","text":"The JS ecosystem supports multiple prominent GraphQL frameworks. supabase-js is unopinionated about your GraphQL tooling and can integrate with all of them. For an example integration, check out the Relay guide , complete with Supabase Auth support.","title":"supabase-js"},{"location":"supabase/#graphiql","text":"If you'd prefer to connect to Supabase GraphQL using an external IDE like GraphiQL, save the HTML snippet below as supabase_graphiql.html and open it in your browser. Be sure to substitute in your PROJECT_REF and API_KEY beneath the EDIT BELOW comment: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 < html > < head > < title > GraphiQL </ title > < link href = \"https://cdnjs.cloudflare.com/ajax/libs/graphiql/2.4.7/graphiql.css\" rel = \"stylesheet\" /> </ head > < body style = \"margin: 0;\" > < div id = \"graphiql\" style = \"height: 100vh;\" ></ div > < script crossorigin src = \"https://unpkg.com/react@18/umd/react.production.min.js\" ></ script > < script crossorigin src = \"https://unpkg.com/react-dom@18/umd/react-dom.production.min.js\" ></ script > < script crossorigin src = \"https://cdnjs.cloudflare.com/ajax/libs/graphiql/2.4.7/graphiql.js\" ></ script > < script > //////////////// // EDIT BELOW // //////////////// const fetcher = GraphiQL . createFetcher ({ url : 'https://<PROJECT_REF>.supabase.co/graphql/v1' , headers : { \"apiKey\" : \"<API_KEY>\" , } }); ReactDOM . render ( React . createElement ( GraphiQL , { fetcher : fetcher }), document . getElementById ( 'graphiql' ), ); </ script > </ body > </ html >","title":"GraphiQL"},{"location":"supabase/#schema-table-visibility","text":"pg_graphql uses Postgres' search_path and permissions system to determine which schemas and entities are exposed in the GraphQL schema. By default on Supabase, tables, views, and functions in the public schema are visible to anonymous ( anon ) and logged in ( authenticated ) roles.","title":"Schema &amp; Table Visibility"},{"location":"supabase/#remove-a-table-from-the-api","text":"To remove a table from the GraphQL API, you can revoke permission on that table from the the relevant role. For example, to remove table foo from the API for anonymous users you could run: 1 revoke all on table public . foo from anon ; You can similarly revoke permissions using the more granular insert , update , delete , and truncate permissions to remove individual entrypoints in the GraphQL API. For example, revoking update permission removes the updateFooCollection entrypoing in the API's Mutation type.","title":"Remove a Table from the API"},{"location":"supabase/#add-a-schema-to-the-api","text":"Adding a schema to the GraphQL API is a two step process. First, we need to add the new schema to the API search path. In the example below, we add a comma separated value for the new app schema: Next, make sure the schema and entities (tables/views/functions) that you intend to expose are accessible by the relevant roles. For example, to match permissions from the public schema: 1 2 3 4 5 6 7 grant usage on schema app to anon , authenticated , service_role ; grant all privileges on all tables in schema app to anon , authenticated , service_role ; grant all privileges on all routines in schema app to anon , authenticated , service_role ; grant all privileges on all sequences in schema app to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on tables to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on routines to anon , authenticated , service_role ; alter default privileges for role postgres in schema app grant all on sequences to anon , authenticated , service_role ; Note that in practice you likely prefer a more secure set of permissions, particularly for anonymous API users.","title":"Add a Schema to the API"},{"location":"supabase/#version-management","text":"To maximize stability, you are in control of when to upgrade your GraphQL API. To see which version of pg_graphql you have, and the highest upgrade version available, execute: 1 select * from pg_available_extensions where name = 'pg_graphql' Which returns a table, for example: name default_version installed_version comment pg_graphql 1.2.0 1.1.0 GraphQL support The default_version is the highest version available on your database. The installed_version is the version currently enabled in your database. If the two differ, as in the example, you can upgrade your installed version by running: 1 2 drop extension pg_graphql ; -- drop version 1.1.0 create extension pg_graphql ; -- install default version 1.2.0 To upgrade your GraphQL API with 0 downtime. When making a decision to upgrade, you can review features of the upgraded version in the changelog . Always test a new version of pg_graphql extensively on a development or staging instance before updating your production instance. pg_graphql follows SemVer, which makes API backwards compatibility relatively safe for minor and patch updates. Even so, it's critical to verify that changes do not negatively impact the specifics of your project's API in other ways, e.g. requests/sec or CPU load.","title":"Version Management"},{"location":"supabase/#local-development","text":"When starting a local project through the Supabase CLI , the output of supabase start provides the information needed to call the GraphQL API directly. You can also use the Supabase Studio url to access the builtin GraphiQL IDE . 1 2 3 4 5 6 7 8 9 10 11 12 > supabase start ... Started supabase local development setup. GraphQL URL: http://localhost:54321/graphql/v1 <-- GraphQL endpoint DB URL: ... Studio URL: http://localhost:54323 <-- Supabase Studio Inbucket URL: ... JWT secret: ... anon key: eyJhbGciOiJIUzI1...<truncated> <-- API_KEY service_role key: ...","title":"Local Development"},{"location":"supabase/#term-reference","text":"","title":"Term Reference"},{"location":"supabase/#project-reference-project_ref","text":"Your Supabase project reference or PROJECT_REF is a 20 digit unique identifier for your project, for example bvykdyhlwawojivopztl . The project reference is used throughout your supabase application including the project's API URL. You can find the project reference in by logging in to Supabase Studio and navigating to Settings > General > Project Settings > Reference ID","title":"Project Reference (PROJECT_REF)"},{"location":"supabase/#api-key-api_key","text":"Your Supabase API Key is a public value that must be sent with every API request. The key is visible in Supabase Studio at Settings > API > Project API keys","title":"API Key (API_KEY)"},{"location":"usage_with_apollo/","text":"This guide will show you how to use pg_graphql with Apollo and GraphQL Code Generator for type-safe GraphQL queries in your React application. Apollo Setup Pre-requisites Follow the Apollo Getting Started Guide . Follow the GraphQL Code Generator Installation Guide . Configuring GraphQL Code Generator Modify your codegen.ts file to reflect the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import type { CodegenConfig } from '@graphql-codegen/cli' import { addTypenameSelectionDocumentTransform } from '@graphql-codegen/client-preset' const config : CodegenConfig = { schema : 'http://localhost:54321/graphql/v1' , // Using the local endpoint, update if needed documents : 'src/**/*.tsx' , overwrite : true , ignoreNoDocuments : true , generates : { 'src/gql/' : { preset : 'client' , documentTransforms : [ addTypenameSelectionDocumentTransform ], plugins : [], config : { scalars : { UUID : 'string' , Date : 'string' , Time : 'string' , Datetime : 'string' , JSON : 'string' , BigInt : 'string' , BigFloat : 'string' , Opaque : 'any' , }, }, }, }, hooks : { afterAllFileWrite : [ 'npm run prettier' ], // optional }, } export default config Configuring Apollo Client This example uses Supabase for the GraphQL server, but pg_graphql can be used independently. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import { ApolloClient , InMemoryCache , createHttpLink , defaultDataIdFromObject } from '@apollo/client' import { setContext } from '@apollo/client/link/context' import { relayStylePagination } from '@apollo/client/utilities' import supabase from './supabase' const cache = new InMemoryCache ({ dataIdFromObject ( responseObject ) { if ( 'nodeId' in responseObject ) { return ` ${ responseObject . nodeId } ` } return defaultDataIdFromObject ( responseObject ) }, possibleTypes : { Node : [ 'Todos' ] } // optional, but useful to specify supertype-subtype relationships typePolicies : { Query : { fields : { todosCollection : relayStylePagination (), // example of paginating a collection node : { read ( _ , { args , toReference }) { const ref = toReference ({ nodeId : args?.nodeId , }) return ref }, }, }, }, }, }) const httpLink = createHttpLink ({ uri : 'http://localhost:54321/graphql/v1' , }) const authLink = setContext ( async ( _ , { headers }) => { const token = ( await supabase . auth . getSession ()). data . session ? . access_token return { headers : { ... headers , Authorization : token ? `Bearer ${ token } ` : '' , }, } }) const apolloClient = new ApolloClient ({ link : authLink.concat ( httpLink ), cache , }) export default apolloClient typePolicies.Query.fields.node is also optional, but useful for reducing cache misses. Learn more about Redirecting to cached data . Example Query 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 import { useQuery } from '@apollo/client' import { graphql } from './gql' const allTodosQueryDocument = graphql ( /* GraphQL */ ` query AllTodos($cursor: Cursor) { todosCollection(first: 10, after: $cursor) { edges { node { nodeId title } } pageInfo { endCursor hasNextPage } } } ` ) const TodoList = () => { const { data , fetchMore } = useQuery ( allTodosQueryDocument ) return ( <> { data ? . thingsCollection ? . edges . map (({ node }) => ( < Todo key = { node . nodeId } title = { node . title } /> ))} { data ? . thingsCollection ? . pageInfo . hasNextPage && ( < Button onClick = {() => { fetchMore ({ variables : { cursor : data ? . thingsCollection ? . pageInfo . endCursor , }, }) }} > Load More < /Button> )} < /> ) } export default TodoList","title":"Usage with Apollo"},{"location":"usage_with_apollo/#apollo-setup","text":"","title":"Apollo Setup"},{"location":"usage_with_apollo/#pre-requisites","text":"Follow the Apollo Getting Started Guide . Follow the GraphQL Code Generator Installation Guide .","title":"Pre-requisites"},{"location":"usage_with_apollo/#configuring-graphql-code-generator","text":"Modify your codegen.ts file to reflect the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import type { CodegenConfig } from '@graphql-codegen/cli' import { addTypenameSelectionDocumentTransform } from '@graphql-codegen/client-preset' const config : CodegenConfig = { schema : 'http://localhost:54321/graphql/v1' , // Using the local endpoint, update if needed documents : 'src/**/*.tsx' , overwrite : true , ignoreNoDocuments : true , generates : { 'src/gql/' : { preset : 'client' , documentTransforms : [ addTypenameSelectionDocumentTransform ], plugins : [], config : { scalars : { UUID : 'string' , Date : 'string' , Time : 'string' , Datetime : 'string' , JSON : 'string' , BigInt : 'string' , BigFloat : 'string' , Opaque : 'any' , }, }, }, }, hooks : { afterAllFileWrite : [ 'npm run prettier' ], // optional }, } export default config","title":"Configuring GraphQL Code Generator"},{"location":"usage_with_apollo/#configuring-apollo-client","text":"This example uses Supabase for the GraphQL server, but pg_graphql can be used independently. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import { ApolloClient , InMemoryCache , createHttpLink , defaultDataIdFromObject } from '@apollo/client' import { setContext } from '@apollo/client/link/context' import { relayStylePagination } from '@apollo/client/utilities' import supabase from './supabase' const cache = new InMemoryCache ({ dataIdFromObject ( responseObject ) { if ( 'nodeId' in responseObject ) { return ` ${ responseObject . nodeId } ` } return defaultDataIdFromObject ( responseObject ) }, possibleTypes : { Node : [ 'Todos' ] } // optional, but useful to specify supertype-subtype relationships typePolicies : { Query : { fields : { todosCollection : relayStylePagination (), // example of paginating a collection node : { read ( _ , { args , toReference }) { const ref = toReference ({ nodeId : args?.nodeId , }) return ref }, }, }, }, }, }) const httpLink = createHttpLink ({ uri : 'http://localhost:54321/graphql/v1' , }) const authLink = setContext ( async ( _ , { headers }) => { const token = ( await supabase . auth . getSession ()). data . session ? . access_token return { headers : { ... headers , Authorization : token ? `Bearer ${ token } ` : '' , }, } }) const apolloClient = new ApolloClient ({ link : authLink.concat ( httpLink ), cache , }) export default apolloClient typePolicies.Query.fields.node is also optional, but useful for reducing cache misses. Learn more about Redirecting to cached data .","title":"Configuring Apollo Client"},{"location":"usage_with_apollo/#example-query","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 import { useQuery } from '@apollo/client' import { graphql } from './gql' const allTodosQueryDocument = graphql ( /* GraphQL */ ` query AllTodos($cursor: Cursor) { todosCollection(first: 10, after: $cursor) { edges { node { nodeId title } } pageInfo { endCursor hasNextPage } } } ` ) const TodoList = () => { const { data , fetchMore } = useQuery ( allTodosQueryDocument ) return ( <> { data ? . thingsCollection ? . edges . map (({ node }) => ( < Todo key = { node . nodeId } title = { node . title } /> ))} { data ? . thingsCollection ? . pageInfo . hasNextPage && ( < Button onClick = {() => { fetchMore ({ variables : { cursor : data ? . thingsCollection ? . pageInfo . endCursor , }, }) }} > Load More < /Button> )} < /> ) } export default TodoList","title":"Example Query"},{"location":"usage_with_relay/","text":"pg_graphql implements the GraphQL Global Object Identification Specification ( Node interface) and the GraphQL Cursor Connections Specification to be compatible with Relay . Relay Setup Pre-requisites Follow the Relay Installation Guide . Configuring the Relay Compiler Modify your relay.config.js file to reflect the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module . exports = { // standard relay config options src : './src' , language : 'typescript' , schema : './data/schema.graphql' , exclude : [ '**/node_modules/**' , '**/__mocks__/**' , '**/__generated__/**' ], // pg_graphql specific options schemaConfig : { nodeInterfaceIdField : 'nodeId' , nodeInterfaceIdVariableName : 'nodeId' , }, customScalars : { UUID : 'string' , Datetime : 'string' , JSON : 'string' , BigInt : 'string' , BigFloat : 'string' , Opaque : 'any' , }, } schemaConfig tells the Relay compiler where to find the nodeId field on the node interface customScalars will improve Relay's type emission Configuring your Relay Environment This example uses Supabase for the GraphQL server, but pg_graphql can be used independently. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import { Environment , FetchFunction , Network , RecordSource , Store , } from 'relay-runtime' import supabase , { SUPABASE_ANON_KEY , SUPABASE_URL } from './supabase' const fetchQuery : FetchFunction = async ( operation , variables ) => { const { data : { session }, } = await supabase . auth . getSession () const response = await fetch ( ` ${ SUPABASE_URL } /graphql/v1` , { method : 'POST' , headers : { 'Content-Type' : 'application/json' , apikey : SUPABASE_ANON_KEY , Authorization : `Bearer ${ session ? . access_token ?? SUPABASE_ANON_KEY } ` , }, body : JSON.stringify ({ query : operation.text , variables , }), }) return await response . json () } const network = Network . create ( fetchQuery ) const store = new Store ( new RecordSource ()) const environment = new Environment ({ network , store , getDataID : ( node ) => node . nodeId , missingFieldHandlers : [ { handle ( field , _record , argValues ) { if ( field . name === 'node' && 'nodeId' in argValues ) { // If field is node(nodeId: $nodeId), look up the record by the value of $nodeId return argValues . nodeId } return undefined }, kind : 'linked' , }, ], }) export default environment getDataID is the most important option to add, as it tells Relay how to store data correctly in the cache. missingFieldHandlers is optional in this example but helps with Rendering Partially Cached Data . Pagination Say you are working on a Todo app and want to add pagination. You can use @connection and @prependNode to do this. Fragment passed to usePaginationFragment() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 fragment TodoList_query on Query @ argumentDefinitions ( cursor: { type: \"Cursor\" } count: { type: \"Int\" , defaultValue: 20 } ) @refetchable ( queryName: \"TodoListPaginationQuery\" ) { todosCollection ( after: $cursor , first: $count ) @connection ( key: \"TodoList_query_todosCollection\" ) { pageInfo { hasNextPage endCursor } edges { cursor node { nodeId ... TodoItem_todos } } } } Mutation to create a new Todo 1 2 3 4 5 6 7 8 mutation TodoCreateMutation ( $input : TodosInsertInput ! , $connections : [ ID !]!) { insertIntoTodosCollection ( objects: [ $input ]) { affectedCount records @ prependNode ( connections: $connections , edgeTypeName: \"TodosEdge\" ) { ... TodoItem_todos } } } Code to call the mutation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import { ConnectionHandler , graphql , useMutation } from 'react-relay' // inside a React component const [ todoCreateMutate , isMutationInFlight ] = useMutation < TodoCreateMutation > ( CreateTodoMutation ) // inside your create todo function const connectionID = ConnectionHandler . getConnectionID ( 'root' , 'TodoList_query_todosCollection' ) todoCreateMutate ({ variables : { input : { // ...new todo data }, connections : [ connectionID ], }, })","title":"Usage with Relay"},{"location":"usage_with_relay/#relay-setup","text":"","title":"Relay Setup"},{"location":"usage_with_relay/#pre-requisites","text":"Follow the Relay Installation Guide .","title":"Pre-requisites"},{"location":"usage_with_relay/#configuring-the-relay-compiler","text":"Modify your relay.config.js file to reflect the following: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 module . exports = { // standard relay config options src : './src' , language : 'typescript' , schema : './data/schema.graphql' , exclude : [ '**/node_modules/**' , '**/__mocks__/**' , '**/__generated__/**' ], // pg_graphql specific options schemaConfig : { nodeInterfaceIdField : 'nodeId' , nodeInterfaceIdVariableName : 'nodeId' , }, customScalars : { UUID : 'string' , Datetime : 'string' , JSON : 'string' , BigInt : 'string' , BigFloat : 'string' , Opaque : 'any' , }, } schemaConfig tells the Relay compiler where to find the nodeId field on the node interface customScalars will improve Relay's type emission","title":"Configuring the Relay Compiler"},{"location":"usage_with_relay/#configuring-your-relay-environment","text":"This example uses Supabase for the GraphQL server, but pg_graphql can be used independently. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import { Environment , FetchFunction , Network , RecordSource , Store , } from 'relay-runtime' import supabase , { SUPABASE_ANON_KEY , SUPABASE_URL } from './supabase' const fetchQuery : FetchFunction = async ( operation , variables ) => { const { data : { session }, } = await supabase . auth . getSession () const response = await fetch ( ` ${ SUPABASE_URL } /graphql/v1` , { method : 'POST' , headers : { 'Content-Type' : 'application/json' , apikey : SUPABASE_ANON_KEY , Authorization : `Bearer ${ session ? . access_token ?? SUPABASE_ANON_KEY } ` , }, body : JSON.stringify ({ query : operation.text , variables , }), }) return await response . json () } const network = Network . create ( fetchQuery ) const store = new Store ( new RecordSource ()) const environment = new Environment ({ network , store , getDataID : ( node ) => node . nodeId , missingFieldHandlers : [ { handle ( field , _record , argValues ) { if ( field . name === 'node' && 'nodeId' in argValues ) { // If field is node(nodeId: $nodeId), look up the record by the value of $nodeId return argValues . nodeId } return undefined }, kind : 'linked' , }, ], }) export default environment getDataID is the most important option to add, as it tells Relay how to store data correctly in the cache. missingFieldHandlers is optional in this example but helps with Rendering Partially Cached Data .","title":"Configuring your Relay Environment"},{"location":"usage_with_relay/#pagination","text":"Say you are working on a Todo app and want to add pagination. You can use @connection and @prependNode to do this. Fragment passed to usePaginationFragment() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 fragment TodoList_query on Query @ argumentDefinitions ( cursor: { type: \"Cursor\" } count: { type: \"Int\" , defaultValue: 20 } ) @refetchable ( queryName: \"TodoListPaginationQuery\" ) { todosCollection ( after: $cursor , first: $count ) @connection ( key: \"TodoList_query_todosCollection\" ) { pageInfo { hasNextPage endCursor } edges { cursor node { nodeId ... TodoItem_todos } } } } Mutation to create a new Todo 1 2 3 4 5 6 7 8 mutation TodoCreateMutation ( $input : TodosInsertInput ! , $connections : [ ID !]!) { insertIntoTodosCollection ( objects: [ $input ]) { affectedCount records @ prependNode ( connections: $connections , edgeTypeName: \"TodosEdge\" ) { ... TodoItem_todos } } } Code to call the mutation 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import { ConnectionHandler , graphql , useMutation } from 'react-relay' // inside a React component const [ todoCreateMutate , isMutationInFlight ] = useMutation < TodoCreateMutation > ( CreateTodoMutation ) // inside your create todo function const connectionID = ConnectionHandler . getConnectionID ( 'root' , 'TodoList_query_todosCollection' ) todoCreateMutate ({ variables : { input : { // ...new todo data }, connections : [ connectionID ], }, })","title":"Pagination"},{"location":"views/","text":"Views, materialized views, and foreign tables can be exposed with pg_graphql. Primary Keys (Required) A primary key is required for an entity to be reflected in the GraphQL schema. Tables can define primary keys with SQL DDL, but primary keys are not available for views, materialized views, or foreign tables. For those entities, you can set a \"fake\" primary key with a comment directive . 1 { \"primary_key_columns\" : [ <colum n _ na me_ 1 > , ... , <colum n _ na me_ n > ]} For example: 1 2 3 4 5 6 7 8 create view \"Person\" as select id , name from \"Account\" ; comment on view \"Person\" is e '@graphql({\"primary_key_columns\": [\"id\"]})' ; tells pg_graphql to treat \"Person\".id as the primary key for the Person entity resulting in the following GraphQL type: 1 2 3 4 5 type Person { nodeId: ID ! id: Int ! name: String ! } Warning Values of the primary key column/s must be unique within the table. If they are not unique, you will experience inconsistent behavior with ID! types, sorting, and pagination. Updatable views are reflected in the Query and Mutation types identically to tables. Non-updatable views are read-only and accessible via the Query type only. Relationships pg_graphql identifies relationships among entities by inspecting foreign keys. Views, materialized views, and foreign tables do not support foreign keys. For this reason, relationships can also be defined in comment directive using the structure: 1 2 3 4 5 6 7 8 9 10 11 12 { \"foreign_keys\" : [ { \"local_name\" : \"foo\" , // optional \"local_columns\" : [ \"account_id\" ], \"foreign_name\" : \"bar\" , // optional \"foreign_schema\" : \"public\" , \"foreign_table\" : \"account\" , \"foreign_columns\" : [ \"id\" ] } ] } For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 create table \"Account\" ( id serial primary key , name text not null ); create table \"EmailAddress\" ( id serial primary key , \"accountId\" int not null , -- note: no foreign key \"isPrimary\" bool not null , address text not null ); comment on table \"EmailAddress\" is e ' @graphql({ \"foreign_keys\": [ { \"local_name\": \"addresses\", \"local_columns\": [\"accountId\"], \"foreign_name\": \"account\", \"foreign_schema\": \"public\", \"foreign_table\": \"Account\", \"foreign_columns\": [\"id\"] } ] })' ; defines a relationship equivalent to the following foreign key 1 2 3 4 5 6 7 8 alter table \"EmailAddress\" add constraint fkey_email_address_to_account foreign key ( \"accountId\" ) references \"Account\" ( \"id\" ); comment on constraint fkey_email_address_to_account on \"EmailAddress\" is E '@graphql({\"foreign_name\": \"account\", \"local_name\": \"addresses\"})' ; yielding the GraphQL types: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type Account { nodeId: ID ! id: Int ! name: String ! addresses ( after: Cursor , before: Cursor , filter: EmailAddressFilter , first: Int , last: Int , orderBy: [ EmailAddressOrderBy !] ): EmailAddressConnection } type EmailAddress { nodeId: ID ! id: Int ! isPrimary: Boolean ! address: String ! accountId: Int ! account: Account ! }","title":"Views"},{"location":"views/#primary-keys-required","text":"A primary key is required for an entity to be reflected in the GraphQL schema. Tables can define primary keys with SQL DDL, but primary keys are not available for views, materialized views, or foreign tables. For those entities, you can set a \"fake\" primary key with a comment directive . 1 { \"primary_key_columns\" : [ <colum n _ na me_ 1 > , ... , <colum n _ na me_ n > ]} For example: 1 2 3 4 5 6 7 8 create view \"Person\" as select id , name from \"Account\" ; comment on view \"Person\" is e '@graphql({\"primary_key_columns\": [\"id\"]})' ; tells pg_graphql to treat \"Person\".id as the primary key for the Person entity resulting in the following GraphQL type: 1 2 3 4 5 type Person { nodeId: ID ! id: Int ! name: String ! } Warning Values of the primary key column/s must be unique within the table. If they are not unique, you will experience inconsistent behavior with ID! types, sorting, and pagination. Updatable views are reflected in the Query and Mutation types identically to tables. Non-updatable views are read-only and accessible via the Query type only.","title":"Primary Keys (Required)"},{"location":"views/#relationships","text":"pg_graphql identifies relationships among entities by inspecting foreign keys. Views, materialized views, and foreign tables do not support foreign keys. For this reason, relationships can also be defined in comment directive using the structure: 1 2 3 4 5 6 7 8 9 10 11 12 { \"foreign_keys\" : [ { \"local_name\" : \"foo\" , // optional \"local_columns\" : [ \"account_id\" ], \"foreign_name\" : \"bar\" , // optional \"foreign_schema\" : \"public\" , \"foreign_table\" : \"account\" , \"foreign_columns\" : [ \"id\" ] } ] } For example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 create table \"Account\" ( id serial primary key , name text not null ); create table \"EmailAddress\" ( id serial primary key , \"accountId\" int not null , -- note: no foreign key \"isPrimary\" bool not null , address text not null ); comment on table \"EmailAddress\" is e ' @graphql({ \"foreign_keys\": [ { \"local_name\": \"addresses\", \"local_columns\": [\"accountId\"], \"foreign_name\": \"account\", \"foreign_schema\": \"public\", \"foreign_table\": \"Account\", \"foreign_columns\": [\"id\"] } ] })' ; defines a relationship equivalent to the following foreign key 1 2 3 4 5 6 7 8 alter table \"EmailAddress\" add constraint fkey_email_address_to_account foreign key ( \"accountId\" ) references \"Account\" ( \"id\" ); comment on constraint fkey_email_address_to_account on \"EmailAddress\" is E '@graphql({\"foreign_name\": \"account\", \"local_name\": \"addresses\"})' ; yielding the GraphQL types: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type Account { nodeId: ID ! id: Int ! name: String ! addresses ( after: Cursor , before: Cursor , filter: EmailAddressFilter , first: Int , last: Int , orderBy: [ EmailAddressOrderBy !] ): EmailAddressConnection } type EmailAddress { nodeId: ID ! id: Int ! isPrimary: Boolean ! address: String ! accountId: Int ! account: Account ! }","title":"Relationships"}]}